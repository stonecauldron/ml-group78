{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.seterr(over='raise', invalid='raise', divide='raise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "DATA_TRAIN_PATH = '../train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "X0, X1, X2, indices0, indices1, indices2 = separate_data(X)\n",
    "y0 = y[indices0]\n",
    "y1 = y[indices1]\n",
    "y2 = y[indices2]\n",
    "overall_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2[0,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters0 = 13000\n",
    "gamma0 = 1e-6\n",
    "lambda_0 = 0\n",
    "degree_0 = 2\n",
    "batch_size0 = 100\n",
    "k = 4\n",
    "current_y = y0\n",
    "current_X = X0\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly_cos_sin_poly(test_x, degree_0, np.array(range(1,19)))\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly_cos_sin_poly(training_x, degree_0, np.array(range(1,19)))\n",
    "\n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_0, gamma0, max_iters0)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_1 = 25000\n",
    "gamma_1 = 0.9e-7\n",
    "lambda_1 = 0\n",
    "degree_1 = 3\n",
    "batch_size1 = 100\n",
    "k = 4\n",
    "current_y = y1\n",
    "current_X = X1\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly_cos_sin_poly(test_x, degree_1, np.array(range(1,23)))\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly_cos_sin_poly(training_x, degree_1, np.array(range(1,23)))\n",
    "\n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_1, gamma_1, max_iters_1)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_2 = 15000\n",
    "gamma_2 = 1e-7\n",
    "lambda_2 = 0.0\n",
    "degree_2 = 3\n",
    "batch_size2 = 100\n",
    "k = 4\n",
    "current_y = y2\n",
    "current_X = X2\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly_cos_sin_poly(test_x, degree_2, np.array(range(1,50)))\n",
    "    \n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly_cos_sin_poly(training_x, degree_2, np.array(range(1,50)))\n",
    "    \n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_2, gamma_2, max_iters_2)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"The overall accuracy: {acc}\\n\".format(acc=np.mean(overall_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "\n",
    "gamma_0 = 1e-6\n",
    "max_iters_0 = 15000\n",
    "degree_0 = 2\n",
    "\n",
    "max_iters_1 = 25000\n",
    "gamma_1 = 0.9e-7\n",
    "degree_1 = 3\n",
    "\n",
    "max_iters_2 = 15000\n",
    "gamma_2 = 1e-7\n",
    "degree_2 = 3\n",
    "\n",
    "max_iters_3 = 15000\n",
    "gamma_3 = 1e-6\n",
    "degree_3 = 3\n",
    "\n",
    "X0, X1, X2, X3, indices0, indices1, indices2, indices3 = separate_data(X)\n",
    "y0 = y[indices0]\n",
    "y1 = y[indices1]\n",
    "y2 = y[indices2]\n",
    "#y3 = y[indices3]\n",
    "\n",
    "\n",
    "phi_X0 = build_poly_cos_sin_poly(X0, degree_0, np.array(range(1,19)))\n",
    "phi_X1 = build_poly_cos_sin_poly(X1, degree_1, np.array(range(1,23)))\n",
    "phi_X2 = build_poly_cos_sin_poly(X2, degree_2, np.array(range(1,30)))\n",
    "#phi_X3 = build_poly(X3, degree_3)\n",
    "\n",
    "w0 = reg_logistic_regression(y0, phi_X0, 0, gamma_0, max_iters_0)\n",
    "w1 = reg_logistic_regression(y1, phi_X1, 0, gamma_1, max_iters_1)\n",
    "w2 = reg_logistic_regression(y2, phi_X2, 0, gamma_2, max_iters_2)\n",
    "#w3 = reg_logistic_regression(y3, phi_X3, 0, gamma_3, max_iters_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "X0_te, X1_te, X2_te, indices0_te, indices1_te, indices2_te = separate_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../submission6.csv' # TODO: fill in desired name of output file for submission\n",
    "ids_test0 = ids_test[indices0_te]\n",
    "ids_test1 = ids_test[indices1_te]\n",
    "ids_test2 = ids_test[indices2_te]\n",
    "#ids_test3 = ids_test[indices3_te]\n",
    "\n",
    "phi_X0_te = build_poly_cos_sin_poly(X0_te, degree_0, np.array(range(1,19)))\n",
    "phi_X1_te = build_poly_cos_sin_poly(X1_te, degree_1, np.array(range(1,23)))\n",
    "phi_X2_te = build_poly_cos_sin_poly(X2_te, degree_2, np.array(range(1,30)))\n",
    "#phi_X3_te = build_poly(X3_te, degree_3)\n",
    "\n",
    "pred0 = predict_labels_log_regression(w0, phi_X0_te)\n",
    "pred1 = predict_labels_log_regression(w1, phi_X1_te)\n",
    "pred2 = predict_labels_log_regression(w2, phi_X2_te)\n",
    "#pred3 = predict_labels_log_regression(w3, phi_X3_te)\n",
    "\n",
    "predictions = np.append(pred0, np.append(pred1, pred2))\n",
    "ids = np.append(ids_test0, np.append(ids_test1, ids_test2))\n",
    "\n",
    "create_csv_submission(ids, predictions, OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
