{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.seterr(over='raise', invalid='raise', divide='raise');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "DATA_TRAIN_PATH = '../train.csv' # TODO: download train data and supply path here \n",
    "y, X, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "X0, X1, X2, X3, indices0, indices1, indices2, indices3 = separate_data(X)\n",
    "y0 = y[indices0]\n",
    "y1 = y[indices1]\n",
    "y2 = y[indices2]\n",
    "y3 = y[indices3]\n",
    "\n",
    "overall_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=46187.23525946155\n",
      "Current iteration=100, the loss=29608.044414346696\n",
      "Current iteration=200, the loss=29186.166471384226\n",
      "Current iteration=300, the loss=29017.842782262862\n",
      "Current iteration=400, the loss=28910.925973800644\n",
      "Current iteration=500, the loss=28829.3666118864\n",
      "Current iteration=600, the loss=28761.120612035236\n",
      "Current iteration=700, the loss=28701.188581964307\n",
      "Current iteration=800, the loss=28647.146053965014\n",
      "Current iteration=900, the loss=28597.644863433816\n",
      "Current iteration=1000, the loss=28551.84582331616\n",
      "Current iteration=1100, the loss=28509.179949521305\n",
      "Current iteration=1200, the loss=28469.236541813694\n",
      "Current iteration=1300, the loss=28431.704977550646\n",
      "Current iteration=1400, the loss=28396.341573961494\n",
      "Current iteration=1500, the loss=28362.94932890321\n",
      "Current iteration=1600, the loss=28331.364867562843\n",
      "Current iteration=1700, the loss=28301.449708075776\n",
      "Current iteration=1800, the loss=28273.08425201797\n",
      "Current iteration=1900, the loss=28246.16355849486\n",
      "Current iteration=2000, the loss=28220.59431680102\n",
      "Current iteration=2100, the loss=28196.292640278018\n",
      "Current iteration=2200, the loss=28173.182431423706\n",
      "Current iteration=2300, the loss=28151.19414952866\n",
      "Current iteration=2400, the loss=28130.263865325032\n",
      "Current iteration=2500, the loss=28110.33252267888\n",
      "Current iteration=2600, the loss=28091.345351444346\n",
      "Current iteration=2700, the loss=28073.251392096266\n",
      "Current iteration=2800, the loss=28056.003104155112\n",
      "Current iteration=2900, the loss=28039.55603834706\n",
      "Current iteration=3000, the loss=28023.868557994203\n",
      "Current iteration=3100, the loss=28008.901599041023\n",
      "Current iteration=3200, the loss=27994.61846089625\n",
      "Current iteration=3300, the loss=27980.98462224722\n",
      "Current iteration=3400, the loss=27967.967577425676\n",
      "Current iteration=3500, the loss=27955.536689933593\n",
      "Current iteration=3600, the loss=27943.663060490246\n",
      "Current iteration=3700, the loss=27932.319407516577\n",
      "Current iteration=3800, the loss=27921.479958387383\n",
      "Current iteration=3900, the loss=27911.120350094265\n",
      "Current iteration=4000, the loss=27901.21753820096\n",
      "Current iteration=4100, the loss=27891.749713157995\n",
      "Current iteration=4200, the loss=27882.69622318814\n",
      "Current iteration=4300, the loss=27874.037503070296\n",
      "Current iteration=4400, the loss=27865.755008241766\n",
      "Current iteration=4500, the loss=27857.83115371538\n",
      "Current iteration=4600, the loss=27850.24925737038\n",
      "Current iteration=4700, the loss=27842.993487228294\n",
      "Current iteration=4800, the loss=27836.048812369656\n",
      "Current iteration=4900, the loss=27829.400957184487\n",
      "Current iteration=5000, the loss=27823.036358682453\n",
      "Current iteration=5100, the loss=27816.942126615882\n",
      "Current iteration=5200, the loss=27811.106006193884\n",
      "Current iteration=5300, the loss=27805.51634318648\n",
      "Current iteration=5400, the loss=27800.162051237086\n",
      "Current iteration=5500, the loss=27795.032581217754\n",
      "Current iteration=5600, the loss=27790.11789247683\n",
      "Current iteration=5700, the loss=27785.40842584143\n",
      "Current iteration=5800, the loss=27780.895078249574\n",
      "Current iteration=5900, the loss=27776.569178896432\n",
      "Current iteration=6000, the loss=27772.422466789925\n",
      "Current iteration=6100, the loss=27768.447069618524\n",
      "Current iteration=6200, the loss=27764.63548384229\n",
      "Current iteration=6300, the loss=27760.980555925467\n",
      "Current iteration=6400, the loss=27757.475464634863\n",
      "Current iteration=6500, the loss=27754.113704334726\n",
      "Current iteration=6600, the loss=27750.889069213263\n",
      "Current iteration=6700, the loss=27747.79563838217\n",
      "Current iteration=6800, the loss=27744.827761793054\n",
      "Current iteration=6900, the loss=27741.980046920828\n",
      "Current iteration=7000, the loss=27739.247346165965\n",
      "Current iteration=7100, the loss=27736.62474493223\n",
      "Current iteration=7200, the loss=27734.107550338827\n",
      "Current iteration=7300, the loss=27731.691280529114\n",
      "Current iteration=7400, the loss=27729.37165454065\n",
      "Current iteration=7500, the loss=27727.144582703564\n",
      "Current iteration=7600, the loss=27725.006157536558\n",
      "Current iteration=7700, the loss=27722.95264511202\n",
      "Current iteration=7800, the loss=27720.98047686338\n",
      "Current iteration=7900, the loss=27719.086241809804\n",
      "Current iteration=8000, the loss=27717.266679174616\n",
      "Current iteration=8100, the loss=27715.518671375772\n",
      "Current iteration=8200, the loss=27713.83923736774\n",
      "Current iteration=8300, the loss=27712.22552631548\n",
      "Current iteration=8400, the loss=27710.674811582445\n",
      "Current iteration=8500, the loss=27709.184485015758\n",
      "Current iteration=8600, the loss=27707.752051512412\n",
      "Current iteration=8700, the loss=27706.37512385164\n",
      "Current iteration=8800, the loss=27705.051417779316\n",
      "Current iteration=8900, the loss=27703.778747330936\n",
      "Current iteration=9000, the loss=27702.555020380954\n",
      "Current iteration=9100, the loss=27701.37823440641\n",
      "Current iteration=9200, the loss=27700.24647245385\n",
      "Current iteration=9300, the loss=27699.157899299127\n",
      "Current iteration=9400, the loss=27698.11075778989\n",
      "Current iteration=9500, the loss=27697.103365361814\n",
      "Current iteration=9600, the loss=27696.13411071945\n",
      "Current iteration=9700, the loss=27695.201450673456\n",
      "Current iteration=9800, the loss=27694.30390712635\n",
      "Current iteration=9900, the loss=27693.44006419924\n",
      "Current iteration=10000, the loss=27692.608565492665\n",
      "Current iteration=10100, the loss=27691.80811147463\n",
      "Current iteration=10200, the loss=27691.037456989743\n",
      "Current iteration=10300, the loss=27690.295408883358\n",
      "Current iteration=10400, the loss=27689.580823735105\n",
      "Current iteration=10500, the loss=27688.892605696492\n",
      "Current iteration=10600, the loss=27688.22970442734\n",
      "Current iteration=10700, the loss=27687.59111312653\n",
      "Current iteration=10800, the loss=27686.975866652123\n",
      "Current iteration=10900, the loss=27686.383039726912\n",
      "Current iteration=11000, the loss=27685.81174522506\n",
      "Current iteration=11100, the loss=27685.26113253592\n",
      "Current iteration=11200, the loss=27684.730386001618\n",
      "Current iteration=11300, the loss=27684.218723424452\n",
      "Current iteration=11400, the loss=27683.72539464134\n",
      "Current iteration=11500, the loss=27683.24968016154\n",
      "Current iteration=11600, the loss=27682.790889865202\n",
      "Current iteration=11700, the loss=27682.348361759556\n",
      "Current iteration=11800, the loss=27681.921460790145\n",
      "Current iteration=11900, the loss=27681.50957770456\n",
      "Current iteration=12000, the loss=27681.112127966193\n",
      "Current iteration=12100, the loss=27680.728550715678\n",
      "Current iteration=12200, the loss=27680.358307777828\n",
      "Current iteration=12300, the loss=27680.000882712036\n",
      "Current iteration=12400, the loss=27679.65577990401\n",
      "Current iteration=12500, the loss=27679.322523697036\n",
      "Current iteration=12600, the loss=27679.00065756098\n",
      "Current iteration=12700, the loss=27678.689743297222\n",
      "Current iteration=12800, the loss=27678.389360277957\n",
      "Current iteration=12900, the loss=27678.09910471833\n",
      "The loss=27677.821347159545\n",
      "Current iteration=0, the loss=46139.848299673955\n",
      "Current iteration=100, the loss=29467.471492720517\n",
      "Current iteration=200, the loss=29025.04746746524\n",
      "Current iteration=300, the loss=28846.245228498457\n",
      "Current iteration=400, the loss=28733.56053637708\n",
      "Current iteration=500, the loss=28649.12093587497\n",
      "Current iteration=600, the loss=28579.882735934996\n",
      "Current iteration=700, the loss=28520.23736646358\n",
      "Current iteration=800, the loss=28467.354791855414\n",
      "Current iteration=900, the loss=28419.604605070315\n",
      "Current iteration=1000, the loss=28375.947060708175\n",
      "Current iteration=1100, the loss=28335.66928037148\n",
      "Current iteration=1200, the loss=28298.256961874788\n",
      "Current iteration=1300, the loss=28263.32493968636\n",
      "Current iteration=1400, the loss=28230.576130439676\n",
      "Current iteration=1500, the loss=28199.775603038546\n",
      "Current iteration=1600, the loss=28170.733418448406\n",
      "Current iteration=1700, the loss=28143.292895864226\n",
      "Current iteration=1800, the loss=28117.32239774467\n",
      "Current iteration=1900, the loss=28092.709473415685\n",
      "Current iteration=2000, the loss=28069.35662124667\n",
      "Current iteration=2100, the loss=28047.178181162122\n",
      "Current iteration=2200, the loss=28026.098027414457\n",
      "Current iteration=2300, the loss=28006.047834430647\n",
      "Current iteration=2400, the loss=27986.965757198595\n",
      "Current iteration=2500, the loss=27968.795414337088\n",
      "Current iteration=2600, the loss=27951.485094190302\n",
      "Current iteration=2700, the loss=27934.987126750406\n",
      "Current iteration=2800, the loss=27919.257380029238\n",
      "Current iteration=2900, the loss=27904.25485072941\n",
      "Current iteration=3000, the loss=27889.94132709108\n",
      "Current iteration=3100, the loss=27876.28110756574\n",
      "Current iteration=3200, the loss=27863.240763147624\n",
      "Current iteration=3300, the loss=27850.788934235305\n",
      "Current iteration=3400, the loss=27838.89615512349\n",
      "Current iteration=3500, the loss=27827.53470086411\n",
      "Current iteration=3600, the loss=27816.67845245054\n",
      "Current iteration=3700, the loss=27806.302777183217\n",
      "Current iteration=3800, the loss=27796.384421753857\n",
      "Current iteration=3900, the loss=27786.901416097866\n",
      "Current iteration=4000, the loss=27777.83298645419\n",
      "Current iteration=4100, the loss=27769.159476371286\n",
      "Current iteration=4200, the loss=27760.862274628562\n",
      "Current iteration=4300, the loss=27752.923749222828\n",
      "Current iteration=4400, the loss=27745.327186711613\n",
      "Current iteration=4500, the loss=27738.056736316998\n",
      "Current iteration=4600, the loss=27731.097358284478\n",
      "Current iteration=4700, the loss=27724.434776063878\n",
      "Current iteration=4800, the loss=27718.05543193932\n",
      "Current iteration=4900, the loss=27711.946445783968\n",
      "Current iteration=5000, the loss=27706.095576656186\n",
      "Current iteration=5100, the loss=27700.4911869879\n",
      "Current iteration=5200, the loss=27695.122209144873\n",
      "Current iteration=5300, the loss=27689.97811416269\n",
      "Current iteration=5400, the loss=27685.04888248396\n",
      "Current iteration=5500, the loss=27680.32497653951\n",
      "Current iteration=5600, the loss=27675.797315032883\n",
      "Current iteration=5700, the loss=27671.45724880013\n",
      "Current iteration=5800, the loss=27667.296538129907\n",
      "Current iteration=5900, the loss=27663.307331438653\n",
      "Current iteration=6000, the loss=27659.482145205275\n",
      "Current iteration=6100, the loss=27655.813845077955\n",
      "Current iteration=6200, the loss=27652.29562807322\n",
      "Current iteration=6300, the loss=27648.92100579372\n",
      "Current iteration=6400, the loss=27645.683788597402\n",
      "Current iteration=6500, the loss=27642.57807065588\n",
      "Current iteration=6600, the loss=27639.59821584475\n",
      "Current iteration=6700, the loss=27636.738844412816\n",
      "Current iteration=6800, the loss=27633.99482038132\n",
      "Current iteration=6900, the loss=27631.361239627717\n",
      "Current iteration=7000, the loss=27628.833418611957\n",
      "Current iteration=7100, the loss=27626.40688370617\n",
      "Current iteration=7200, the loss=27624.07736109116\n",
      "Current iteration=7300, the loss=27621.840767186375\n",
      "Current iteration=7400, the loss=27619.69319958124\n",
      "Current iteration=7500, the loss=27617.630928438855\n",
      "Current iteration=7600, the loss=27615.650388344573\n",
      "Current iteration=7700, the loss=27613.74817057365\n",
      "Current iteration=7800, the loss=27611.921015754175\n",
      "Current iteration=7900, the loss=27610.165806902976\n",
      "Current iteration=8000, the loss=27608.47956281313\n",
      "Current iteration=8100, the loss=27606.85943177399\n",
      "Current iteration=8200, the loss=27605.302685604933\n",
      "Current iteration=8300, the loss=27603.80671398558\n",
      "Current iteration=8400, the loss=27602.369019066533\n",
      "Current iteration=8500, the loss=27600.98721034514\n",
      "Current iteration=8600, the loss=27599.65899979224\n",
      "Current iteration=8700, the loss=27598.38219721613\n",
      "Current iteration=8800, the loss=27597.154705851633\n",
      "Current iteration=8900, the loss=27595.974518161696\n",
      "Current iteration=9000, the loss=27594.839711841043\n",
      "Current iteration=9100, the loss=27593.748446010784\n",
      "Current iteration=9200, the loss=27592.69895759428\n",
      "Current iteration=9300, the loss=27591.68955786506\n",
      "Current iteration=9400, the loss=27590.718629157553\n",
      "Current iteration=9500, the loss=27589.784621732644\n",
      "Current iteration=9600, the loss=27588.8860507902\n",
      "Current iteration=9700, the loss=27588.021493620792\n",
      "Current iteration=9800, the loss=27587.189586890032\n",
      "Current iteration=9900, the loss=27586.38902404858\n",
      "Current iteration=10000, the loss=27585.618552861808\n",
      "Current iteration=10100, the loss=27584.876973052873\n",
      "Current iteration=10200, the loss=27584.163134054004\n",
      "Current iteration=10300, the loss=27583.475932860336\n",
      "Current iteration=10400, the loss=27582.814311981452\n",
      "Current iteration=10500, the loss=27582.177257485906\n",
      "Current iteration=10600, the loss=27581.5637971341\n",
      "Current iteration=10700, the loss=27580.97299859532\n",
      "Current iteration=10800, the loss=27580.403967744947\n",
      "Current iteration=10900, the loss=27579.855847037852\n",
      "Current iteration=11000, the loss=27579.327813954522\n",
      "Current iteration=11100, the loss=27578.819079516332\n",
      "Current iteration=11200, the loss=27578.328886866693\n",
      "Current iteration=11300, the loss=27577.85650991519\n",
      "Current iteration=11400, the loss=27577.401252041345\n",
      "Current iteration=11500, the loss=27576.96244485567\n",
      "Current iteration=11600, the loss=27576.539447015\n",
      "Current iteration=11700, the loss=27576.131643089757\n",
      "Current iteration=11800, the loss=27575.73844248068\n",
      "Current iteration=11900, the loss=27575.359278382806\n",
      "Current iteration=12000, the loss=27574.993606794436\n",
      "Current iteration=12100, the loss=27574.640905569067\n",
      "Current iteration=12200, the loss=27574.300673508395\n",
      "Current iteration=12300, the loss=27573.972429494388\n",
      "Current iteration=12400, the loss=27573.655711658786\n",
      "Current iteration=12500, the loss=27573.35007658825\n",
      "Current iteration=12600, the loss=27573.05509856357\n",
      "Current iteration=12700, the loss=27572.770368831465\n",
      "Current iteration=12800, the loss=27572.495494907373\n",
      "Current iteration=12900, the loss=27572.23009990804\n",
      "The loss=27571.976340716024\n",
      "Current iteration=0, the loss=46276.58279824554\n",
      "Current iteration=100, the loss=29796.014310347935\n",
      "Current iteration=200, the loss=29385.99740920064\n",
      "Current iteration=300, the loss=29219.81482516333\n",
      "Current iteration=400, the loss=29112.79711600761\n",
      "Current iteration=500, the loss=29030.552759304388\n",
      "Current iteration=600, the loss=28961.506928338746\n",
      "Current iteration=700, the loss=28900.84497341797\n",
      "Current iteration=800, the loss=28846.198159522904\n",
      "Current iteration=900, the loss=28796.219756246075\n",
      "Current iteration=1000, the loss=28750.054091542348\n",
      "Current iteration=1100, the loss=28707.11269760761\n",
      "Current iteration=1200, the loss=28666.96744454759\n",
      "Current iteration=1300, the loss=28629.29345270496\n",
      "Current iteration=1400, the loss=28593.835726895166\n",
      "Current iteration=1500, the loss=28560.38833390335\n",
      "Current iteration=1600, the loss=28528.780799193784\n",
      "Current iteration=1700, the loss=28498.868928473476\n",
      "Current iteration=1800, the loss=28470.528464130457\n",
      "Current iteration=1900, the loss=28443.650614711372\n",
      "Current iteration=2000, the loss=28418.13884950689\n",
      "Current iteration=2100, the loss=28393.906562014516\n",
      "Current iteration=2200, the loss=28370.875338356753\n",
      "Current iteration=2300, the loss=28348.97365204252\n",
      "Current iteration=2400, the loss=28328.135862698975\n",
      "Current iteration=2500, the loss=28308.30143407691\n",
      "Current iteration=2600, the loss=28289.41431218043\n",
      "Current iteration=2700, the loss=28271.42242186066\n",
      "Current iteration=2800, the loss=28254.277252279993\n",
      "Current iteration=2900, the loss=28237.933510038732\n",
      "Current iteration=3000, the loss=28222.348824619534\n",
      "Current iteration=3100, the loss=28207.48349493306\n",
      "Current iteration=3200, the loss=28193.300268672378\n",
      "Current iteration=3300, the loss=28179.764148270682\n",
      "Current iteration=3400, the loss=28166.842218757763\n",
      "Current iteration=3500, the loss=28154.503493898235\n",
      "Current iteration=3600, the loss=28142.718777791782\n",
      "Current iteration=3700, the loss=28131.460539704276\n",
      "Current iteration=3800, the loss=28120.702800339564\n",
      "Current iteration=3900, the loss=28110.42102809527\n",
      "Current iteration=4000, the loss=28100.592044101482\n",
      "Current iteration=4100, the loss=28091.193935040003\n",
      "Current iteration=4200, the loss=28082.205972898206\n",
      "Current iteration=4300, the loss=28073.60854093609\n",
      "Current iteration=4400, the loss=28065.38306524601\n",
      "Current iteration=4500, the loss=28057.511951366807\n",
      "Current iteration=4600, the loss=28049.97852548214\n",
      "Current iteration=4700, the loss=28042.766979789936\n",
      "Current iteration=4800, the loss=28035.862321677436\n",
      "Current iteration=4900, the loss=28029.250326377507\n",
      "Current iteration=5000, the loss=28022.917492816854\n",
      "Current iteration=5100, the loss=28016.85100239652\n",
      "Current iteration=5200, the loss=28011.038680472113\n",
      "Current iteration=5300, the loss=28005.468960323084\n",
      "Current iteration=5400, the loss=28000.130849421417\n",
      "Current iteration=5500, the loss=27995.01389782705\n",
      "Current iteration=5600, the loss=27990.10816855347\n",
      "Current iteration=5700, the loss=27985.404209760713\n",
      "Current iteration=5800, the loss=27980.89302864522\n",
      "Current iteration=5900, the loss=27976.566066907355\n",
      "Current iteration=6000, the loss=27972.41517768718\n",
      "Current iteration=6100, the loss=27968.432603868012\n",
      "Current iteration=6200, the loss=27964.610957655455\n",
      "Current iteration=6300, the loss=27960.943201346592\n",
      "Current iteration=6400, the loss=27957.42262921122\n",
      "Current iteration=6500, the loss=27954.042850412116\n",
      "Current iteration=6600, the loss=27950.797772897604\n",
      "Current iteration=6700, the loss=27947.68158820425\n",
      "Current iteration=6800, the loss=27944.688757111973\n",
      "Current iteration=6900, the loss=27941.81399609826\n",
      "Current iteration=7000, the loss=27939.05226454178\n",
      "Current iteration=7100, the loss=27936.398752629306\n",
      "Current iteration=7200, the loss=27933.84886992299\n",
      "Current iteration=7300, the loss=27931.398234547843\n",
      "Current iteration=7400, the loss=27929.042662962464\n",
      "Current iteration=7500, the loss=27926.778160277932\n",
      "Current iteration=7600, the loss=27924.6009110925\n",
      "Current iteration=7700, the loss=27922.507270811875\n",
      "Current iteration=7800, the loss=27920.493757426637\n",
      "Current iteration=7900, the loss=27918.557043720335\n",
      "Current iteration=8000, the loss=27916.693949883425\n",
      "Current iteration=8100, the loss=27914.901436509983\n",
      "Current iteration=8200, the loss=27913.176597955186\n",
      "Current iteration=8300, the loss=27911.516656033455\n",
      "Current iteration=8400, the loss=27909.91895403791\n",
      "Current iteration=8500, the loss=27908.38095106342\n",
      "Current iteration=8600, the loss=27906.90021661624\n",
      "Current iteration=8700, the loss=27905.474425494533\n",
      "Current iteration=8800, the loss=27904.101352924918\n",
      "Current iteration=8900, the loss=27902.77886994098\n",
      "Current iteration=9000, the loss=27901.50493899084\n",
      "Current iteration=9100, the loss=27900.277609761266\n",
      "Current iteration=9200, the loss=27899.09501520679\n",
      "Current iteration=9300, the loss=27897.95536777278\n",
      "Current iteration=9400, the loss=27896.856955802446\n",
      "Current iteration=9500, the loss=27895.798140117753\n",
      "Current iteration=9600, the loss=27894.77735076537\n",
      "Current iteration=9700, the loss=27893.793083918867\n",
      "Current iteration=9800, the loss=27892.84389892914\n",
      "Current iteration=9900, the loss=27891.92841551535\n",
      "Current iteration=10000, the loss=27891.04531108916\n",
      "Current iteration=10100, the loss=27890.193318205453\n",
      "Current iteration=10200, the loss=27889.37122213305\n",
      "Current iteration=10300, the loss=27888.577858539415\n",
      "Current iteration=10400, the loss=27887.81211128347\n",
      "Current iteration=10500, the loss=27887.072910311224\n",
      "Current iteration=10600, the loss=27886.359229649002\n",
      "Current iteration=10700, the loss=27885.670085489353\n",
      "Current iteration=10800, the loss=27885.00453436518\n",
      "Current iteration=10900, the loss=27884.36167140762\n",
      "Current iteration=11000, the loss=27883.740628683612\n",
      "Current iteration=11100, the loss=27883.140573609264\n",
      "Current iteration=11200, the loss=27882.5607074352\n",
      "Current iteration=11300, the loss=27882.00026380061\n",
      "Current iteration=11400, the loss=27881.4585073525\n",
      "Current iteration=11500, the loss=27880.93473242707\n",
      "Current iteration=11600, the loss=27880.42826179022\n",
      "Current iteration=11700, the loss=27879.93844543437\n",
      "Current iteration=11800, the loss=27879.46465942896\n",
      "Current iteration=11900, the loss=27879.006304821996\n",
      "Current iteration=12000, the loss=27878.562806590286\n",
      "Current iteration=12100, the loss=27878.13361263602\n",
      "Current iteration=12200, the loss=27877.718192827677\n",
      "Current iteration=12300, the loss=27877.31603808292\n",
      "Current iteration=12400, the loss=27876.926659491808\n",
      "Current iteration=12500, the loss=27876.549587478243\n",
      "Current iteration=12600, the loss=27876.184370998028\n",
      "Current iteration=12700, the loss=27875.830576771692\n",
      "Current iteration=12800, the loss=27875.48778855067\n",
      "Current iteration=12900, the loss=27875.155606415217\n",
      "The loss=27874.83681633215\n",
      "Current iteration=0, the loss=46000.723571417344\n",
      "Current iteration=100, the loss=29879.068842590994\n",
      "Current iteration=200, the loss=29462.046421582672\n",
      "Current iteration=300, the loss=29295.080240182724\n",
      "Current iteration=400, the loss=29188.41813419973\n",
      "Current iteration=500, the loss=29106.64514021906\n",
      "Current iteration=600, the loss=29037.966741774937\n",
      "Current iteration=700, the loss=28977.537588578478\n",
      "Current iteration=800, the loss=28923.014698932497\n",
      "Current iteration=900, the loss=28873.084713651835\n",
      "Current iteration=1000, the loss=28826.919346024468\n",
      "Current iteration=1100, the loss=28783.94993224417\n",
      "Current iteration=1200, the loss=28743.761972681346\n",
      "Current iteration=1300, the loss=28706.039730318487\n",
      "Current iteration=1400, the loss=28670.53421035003\n",
      "Current iteration=1500, the loss=28637.043307347114\n",
      "Current iteration=1600, the loss=28605.398880726716\n",
      "Current iteration=1700, the loss=28575.45804882204\n",
      "Current iteration=1800, the loss=28547.097174695824\n",
      "Current iteration=1900, the loss=28520.207625612653\n",
      "Current iteration=2000, the loss=28494.692728159887\n",
      "Current iteration=2100, the loss=28470.465543381262\n",
      "Current iteration=2200, the loss=28447.447212344217\n",
      "Current iteration=2300, the loss=28425.565703626737\n",
      "Current iteration=2400, the loss=28404.754847518747\n",
      "Current iteration=2500, the loss=28384.953577354718\n",
      "Current iteration=2600, the loss=28366.105322483258\n",
      "Current iteration=2700, the loss=28348.157513824546\n",
      "Current iteration=2800, the loss=28331.0611742827\n",
      "Current iteration=2900, the loss=28314.77057412364\n",
      "Current iteration=3000, the loss=28299.242936902563\n",
      "Current iteration=3100, the loss=28284.43818537205\n",
      "Current iteration=3200, the loss=28270.318719525396\n",
      "Current iteration=3300, the loss=28256.849220873184\n",
      "Current iteration=3400, the loss=28243.996478450637\n",
      "Current iteration=3500, the loss=28231.729233070208\n",
      "Current iteration=3600, the loss=28220.018037081467\n",
      "Current iteration=3700, the loss=28208.835127455648\n",
      "Current iteration=3800, the loss=28198.154310430113\n",
      "Current iteration=3900, the loss=28187.95085626696\n",
      "Current iteration=4000, the loss=28178.201402925708\n",
      "Current iteration=4100, the loss=28168.88386764331\n",
      "Current iteration=4200, the loss=28159.977365567447\n",
      "Current iteration=4300, the loss=28151.462134712165\n",
      "Current iteration=4400, the loss=28143.31946660536\n",
      "Current iteration=4500, the loss=28135.53164207944\n",
      "Current iteration=4600, the loss=28128.081871725873\n",
      "Current iteration=4700, the loss=28120.954240591283\n",
      "Current iteration=4800, the loss=28114.133656741913\n",
      "Current iteration=4900, the loss=28107.60580336477\n",
      "Current iteration=5000, the loss=28101.357094109717\n",
      "Current iteration=5100, the loss=28095.374631407514\n",
      "Current iteration=5200, the loss=28089.646167525974\n",
      "Current iteration=5300, the loss=28084.16006814959\n",
      "Current iteration=5400, the loss=28078.905278289098\n",
      "Current iteration=5500, the loss=28073.87129034504\n",
      "Current iteration=5600, the loss=28069.04811416603\n",
      "Current iteration=5700, the loss=28064.426248956304\n",
      "Current iteration=5800, the loss=28059.996656900134\n",
      "Current iteration=5900, the loss=28055.750738381765\n",
      "Current iteration=6000, the loss=28051.68030869\n",
      "Current iteration=6100, the loss=28047.77757610557\n",
      "Current iteration=6200, the loss=28044.03512127744\n",
      "Current iteration=6300, the loss=28040.445877802158\n",
      "Current iteration=6400, the loss=28037.0031139265\n",
      "Current iteration=6500, the loss=28033.700415300158\n",
      "Current iteration=6600, the loss=28030.531668710566\n",
      "Current iteration=6700, the loss=28027.491046737112\n",
      "Current iteration=6800, the loss=28024.5729932665\n",
      "Current iteration=6900, the loss=28021.772209815255\n",
      "Current iteration=7000, the loss=28019.083642609297\n",
      "Current iteration=7100, the loss=28016.502470373936\n",
      "Current iteration=7200, the loss=28014.024092790823\n",
      "Current iteration=7300, the loss=28011.644119581684\n",
      "Current iteration=7400, the loss=28009.35836018102\n",
      "Current iteration=7500, the loss=28007.16281396268\n",
      "Current iteration=7600, the loss=28005.053660987687\n",
      "Current iteration=7700, the loss=28003.027253242486\n",
      "Current iteration=7800, the loss=28001.080106339195\n",
      "Current iteration=7900, the loss=27999.208891651\n",
      "Current iteration=8000, the loss=27997.410428857704\n",
      "Current iteration=8100, the loss=27995.681678877914\n",
      "Current iteration=8200, the loss=27994.01973716601\n",
      "Current iteration=8300, the loss=27992.421827353217\n",
      "Current iteration=8400, the loss=27990.885295213495\n",
      "Current iteration=8500, the loss=27989.407602936146\n",
      "Current iteration=8600, the loss=27987.98632368813\n",
      "Current iteration=8700, the loss=27986.619136450077\n",
      "Current iteration=8800, the loss=27985.303821111043\n",
      "Current iteration=8900, the loss=27984.038253807896\n",
      "Current iteration=9000, the loss=27982.82040249601\n",
      "Current iteration=9100, the loss=27981.64832273889\n",
      "Current iteration=9200, the loss=27980.520153704863\n",
      "Current iteration=9300, the loss=27979.434114359934\n",
      "Current iteration=9400, the loss=27978.388499846238\n",
      "Current iteration=9500, the loss=27977.381678036414\n",
      "Current iteration=9600, the loss=27976.41208625456\n",
      "Current iteration=9700, the loss=27975.478228155127\n",
      "Current iteration=9800, the loss=27974.578670751507\n",
      "Current iteration=9900, the loss=27973.71204158652\n",
      "Current iteration=10000, the loss=27972.877026037604\n",
      "Current iteration=10100, the loss=27972.072364749674\n",
      "Current iteration=10200, the loss=27971.29685118918\n",
      "Current iteration=10300, the loss=27970.54932931325\n",
      "Current iteration=10400, the loss=27969.828691348015\n",
      "Current iteration=10500, the loss=27969.133875670705\n",
      "Current iteration=10600, the loss=27968.463864790232\n",
      "Current iteration=10700, the loss=27967.817683421377\n",
      "Current iteration=10800, the loss=27967.194396647974\n",
      "Current iteration=10900, the loss=27966.593108170626\n",
      "Current iteration=11000, the loss=27966.01295863483\n",
      "Current iteration=11100, the loss=27965.45312403549\n",
      "Current iteration=11200, the loss=27964.912814194216\n",
      "Current iteration=11300, the loss=27964.391271305783\n",
      "Current iteration=11400, the loss=27963.887768550336\n",
      "Current iteration=11500, the loss=27963.401608768363\n",
      "Current iteration=11600, the loss=27962.932123195184\n",
      "Current iteration=11700, the loss=27962.478670252312\n",
      "Current iteration=11800, the loss=27962.040634392833\n",
      "Current iteration=11900, the loss=27961.617424998243\n",
      "Current iteration=12000, the loss=27961.208475324478\n",
      "Current iteration=12100, the loss=27960.81324149453\n",
      "Current iteration=12200, the loss=27960.431201535743\n",
      "Current iteration=12300, the loss=27960.061854459476\n",
      "Current iteration=12400, the loss=27959.704719381312\n",
      "Current iteration=12500, the loss=27959.359334679833\n",
      "Current iteration=12600, the loss=27959.02525719221\n",
      "Current iteration=12700, the loss=27958.70206144489\n",
      "Current iteration=12800, the loss=27958.38933891778\n",
      "Current iteration=12900, the loss=27958.086697340397\n",
      "The loss=27957.7966425556\n",
      "Training error: 27770.60778669083\n",
      "Test error: 9285.991446805176\n",
      "Classification accuracy: 0.8352350068059893\n"
     ]
    }
   ],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_0 = 13000\n",
    "gamma_0 = 1e-6\n",
    "lambda_0 = 0\n",
    "degree_0 = 2\n",
    "batch_size0 = 100\n",
    "k = 4\n",
    "current_y = y0\n",
    "current_X = X0\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly(test_x, degree_0)\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly(training_x, degree_0)\n",
    "\n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_0, gamma0, max_iters0)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=39301.053110612665\n",
      "Current iteration=100, the loss=33887.81607392824\n",
      "Current iteration=200, the loss=32770.19875464415\n",
      "Current iteration=300, the loss=31300.689909847337\n",
      "Current iteration=400, the loss=30994.446457904032\n",
      "Current iteration=500, the loss=30499.38100425284\n",
      "Current iteration=600, the loss=30051.542864848438\n",
      "Current iteration=700, the loss=29648.387436684185\n",
      "Current iteration=800, the loss=29359.77393393892\n",
      "Current iteration=900, the loss=29136.008401918\n",
      "Current iteration=1000, the loss=28947.158543872025\n",
      "Current iteration=1100, the loss=28785.561886004572\n",
      "Current iteration=1200, the loss=28645.686168554283\n",
      "Current iteration=1300, the loss=28523.43557767925\n",
      "Current iteration=1400, the loss=28415.717546463144\n",
      "Current iteration=1500, the loss=28320.133926955812\n",
      "Current iteration=1600, the loss=28234.77810288683\n",
      "Current iteration=1700, the loss=28158.11189697717\n",
      "Current iteration=1800, the loss=28088.884942615703\n",
      "Current iteration=1900, the loss=28026.074494571483\n",
      "Current iteration=2000, the loss=27968.83838705613\n",
      "Current iteration=2100, the loss=27916.477766736774\n",
      "Current iteration=2200, the loss=27868.407749560807\n",
      "Current iteration=2300, the loss=27824.134649507014\n",
      "Current iteration=2400, the loss=27783.23849323425\n",
      "Current iteration=2500, the loss=27745.35961953986\n",
      "Current iteration=2600, the loss=27710.18833893747\n",
      "Current iteration=2700, the loss=27677.4568430281\n",
      "Current iteration=2800, the loss=27646.932759492738\n",
      "Current iteration=2900, the loss=27618.413927421392\n",
      "Current iteration=3000, the loss=27591.724111226125\n",
      "Current iteration=3100, the loss=27566.70946659935\n",
      "Current iteration=3200, the loss=27543.23558800837\n",
      "Current iteration=3300, the loss=27521.184838243134\n",
      "Current iteration=3400, the loss=27500.453300005378\n",
      "Current iteration=3500, the loss=27480.946241795158\n",
      "Current iteration=3600, the loss=27462.570450545034\n",
      "Current iteration=3700, the loss=27446.502152319415\n",
      "Current iteration=3800, the loss=27400.883479200533\n",
      "Current iteration=3900, the loss=27440.71667586128\n",
      "Current iteration=4000, the loss=27365.75071391496\n",
      "Current iteration=4100, the loss=27418.40030281596\n",
      "Current iteration=4200, the loss=27351.430083910192\n",
      "Current iteration=4300, the loss=27344.275266176533\n",
      "Current iteration=4400, the loss=27384.501119808578\n",
      "Current iteration=4500, the loss=27343.092410330188\n",
      "Current iteration=4600, the loss=27284.670583667626\n",
      "Current iteration=4700, the loss=27279.347511846463\n",
      "Current iteration=4800, the loss=27304.587380088087\n",
      "Current iteration=4900, the loss=27322.05423083208\n",
      "Current iteration=5000, the loss=27326.963674715385\n",
      "Current iteration=5100, the loss=27313.457181491176\n",
      "Current iteration=5200, the loss=27284.76411015222\n",
      "Current iteration=5300, the loss=27221.041669659484\n",
      "Current iteration=5400, the loss=27183.479519655262\n",
      "Current iteration=5500, the loss=27238.078898407606\n",
      "Current iteration=5600, the loss=27261.919954521934\n",
      "Current iteration=5700, the loss=27206.664241287675\n",
      "Current iteration=5800, the loss=27152.576241175822\n",
      "Current iteration=5900, the loss=27232.133379074836\n",
      "Current iteration=6000, the loss=27222.27453053874\n",
      "Current iteration=6100, the loss=27136.580935443333\n",
      "Current iteration=6200, the loss=27219.144267092193\n",
      "Current iteration=6300, the loss=27175.040099745012\n",
      "Current iteration=6400, the loss=27159.9784113847\n",
      "Current iteration=6500, the loss=27191.39367453754\n",
      "Current iteration=6600, the loss=27124.731488693258\n",
      "Current iteration=6700, the loss=27190.953597030944\n",
      "Current iteration=6800, the loss=27118.03345727927\n",
      "Current iteration=6900, the loss=27167.451824174193\n",
      "Current iteration=7000, the loss=27145.25540676033\n",
      "Current iteration=7100, the loss=27114.129252207076\n",
      "Current iteration=7200, the loss=27178.16644004998\n",
      "Current iteration=7300, the loss=27090.719611854372\n",
      "Current iteration=7400, the loss=27119.45856533909\n",
      "Current iteration=7500, the loss=27167.999577626117\n",
      "Current iteration=7600, the loss=27106.987925812984\n",
      "Current iteration=7700, the loss=27071.744409631454\n",
      "Current iteration=7800, the loss=27115.281219087716\n",
      "Current iteration=7900, the loss=27151.72827830986\n",
      "Current iteration=8000, the loss=27148.194723483997\n",
      "Current iteration=8100, the loss=27105.61887207908\n",
      "Current iteration=8200, the loss=27084.607211679522\n",
      "Current iteration=8300, the loss=27058.07371957053\n",
      "Current iteration=8400, the loss=27046.122091837777\n",
      "Current iteration=8500, the loss=27044.138317315133\n",
      "Current iteration=8600, the loss=27043.462256569816\n",
      "Current iteration=8700, the loss=27043.526096636713\n",
      "Current iteration=8800, the loss=27044.489592558508\n",
      "Current iteration=8900, the loss=27047.763232708967\n",
      "Current iteration=9000, the loss=27065.866863244875\n",
      "Current iteration=9100, the loss=27104.68307732858\n",
      "Current iteration=9200, the loss=27123.533417818555\n",
      "Current iteration=9300, the loss=27095.762809425818\n",
      "Current iteration=9400, the loss=27046.683874573082\n",
      "Current iteration=9500, the loss=27030.570772977284\n",
      "Current iteration=9600, the loss=27100.175224276732\n",
      "Current iteration=9700, the loss=27094.767298670256\n",
      "Current iteration=9800, the loss=27027.995937714313\n",
      "Current iteration=9900, the loss=27078.89936831876\n",
      "Current iteration=10000, the loss=27087.014394640442\n",
      "Current iteration=10100, the loss=27010.8544504562\n",
      "Current iteration=10200, the loss=27105.584259685493\n",
      "Current iteration=10300, the loss=27029.615208770174\n",
      "Current iteration=10400, the loss=27089.086046596058\n",
      "Current iteration=10500, the loss=27036.109186506328\n",
      "Current iteration=10600, the loss=27083.828875632025\n",
      "Current iteration=10700, the loss=27027.101319731057\n",
      "Current iteration=10800, the loss=27095.136699409177\n",
      "Current iteration=10900, the loss=27004.38626829057\n",
      "Current iteration=11000, the loss=27084.237798854032\n",
      "Current iteration=11100, the loss=27032.30218508906\n",
      "Current iteration=11200, the loss=27026.252965654166\n",
      "Current iteration=11300, the loss=27088.834094444628\n",
      "Current iteration=11400, the loss=27021.381172674726\n",
      "Current iteration=11500, the loss=27017.926148448478\n",
      "Current iteration=11600, the loss=27076.557349802926\n",
      "Current iteration=11700, the loss=27068.633731192574\n",
      "Current iteration=11800, the loss=26990.109788394686\n",
      "Current iteration=11900, the loss=27016.462302942924\n",
      "The loss=26955.30189209446\n",
      "Current iteration=0, the loss=39244.09685075483\n",
      "Current iteration=100, the loss=33648.661198522765\n",
      "Current iteration=200, the loss=32252.182507435773\n",
      "Current iteration=300, the loss=31355.723123367025\n",
      "Current iteration=400, the loss=30655.781867100366\n",
      "Current iteration=500, the loss=30131.32397112653\n",
      "Current iteration=600, the loss=29751.333401519143\n",
      "Current iteration=700, the loss=29435.212084783634\n",
      "Current iteration=800, the loss=29172.040683072657\n",
      "Current iteration=900, the loss=28961.96988574669\n",
      "Current iteration=1000, the loss=28776.774935176567\n",
      "Current iteration=1100, the loss=28629.760461232858\n",
      "Current iteration=1200, the loss=28486.72847788113\n",
      "Current iteration=1300, the loss=28373.571363598297\n",
      "Current iteration=1400, the loss=28266.197513630537\n",
      "Current iteration=1500, the loss=28174.707371851346\n",
      "Current iteration=1600, the loss=28095.0092438335\n",
      "Current iteration=1700, the loss=28022.06332593653\n",
      "Current iteration=1800, the loss=27959.631003624043\n",
      "Current iteration=1900, the loss=27904.26148374362\n",
      "Current iteration=2000, the loss=27849.087360822537\n",
      "Current iteration=2100, the loss=27803.509420421185\n",
      "Current iteration=2200, the loss=27756.70449274331\n",
      "Current iteration=2300, the loss=27714.823930031027\n",
      "Current iteration=2400, the loss=27675.797715860637\n",
      "Current iteration=2500, the loss=27639.66460115891\n",
      "Current iteration=2600, the loss=27606.12213081819\n",
      "Current iteration=2700, the loss=27574.9016179656\n",
      "Current iteration=2800, the loss=27545.77346013746\n",
      "Current iteration=2900, the loss=27518.539831080987\n",
      "Current iteration=3000, the loss=27493.02653143984\n",
      "Current iteration=3100, the loss=27469.074202775355\n",
      "Current iteration=3200, the loss=27446.535867709936\n",
      "Current iteration=3300, the loss=27425.290165801307\n",
      "Current iteration=3400, the loss=27405.243995626264\n",
      "Current iteration=3500, the loss=27386.31454209094\n",
      "Current iteration=3600, the loss=27368.421914675797\n",
      "Current iteration=3700, the loss=27351.491560329945\n",
      "Current iteration=3800, the loss=27335.45551832624\n",
      "Current iteration=3900, the loss=27320.252019955766\n",
      "Current iteration=4000, the loss=27305.82478809493\n",
      "Current iteration=4100, the loss=27292.122401634515\n",
      "Current iteration=4200, the loss=27279.097750318208\n",
      "Current iteration=4300, the loss=27266.707566801684\n",
      "Current iteration=4400, the loss=27254.912023141806\n",
      "Current iteration=4500, the loss=27243.674381230245\n",
      "Current iteration=4600, the loss=27232.960688606123\n",
      "Current iteration=4700, the loss=27222.73951263082\n",
      "Current iteration=4800, the loss=27212.98170725403\n",
      "Current iteration=4900, the loss=27203.660207603833\n",
      "Current iteration=5000, the loss=27194.74984843895\n",
      "Current iteration=5100, the loss=27186.227203150826\n",
      "Current iteration=5200, the loss=27178.070440524956\n",
      "Current iteration=5300, the loss=27170.259196892875\n",
      "Current iteration=5400, the loss=27162.774461649562\n",
      "Current iteration=5500, the loss=27155.59847439097\n",
      "Current iteration=5600, the loss=27148.71463215932\n",
      "Current iteration=5700, the loss=27142.107405478357\n",
      "Current iteration=5800, the loss=27135.762262027485\n",
      "Current iteration=5900, the loss=27129.66559694899\n",
      "Current iteration=6000, the loss=27123.804668911056\n",
      "Current iteration=6100, the loss=27118.167541166375\n",
      "Current iteration=6200, the loss=27112.74302695393\n",
      "Current iteration=6300, the loss=27107.520638691145\n",
      "Current iteration=6400, the loss=27102.49054049844\n",
      "Current iteration=6500, the loss=27097.643503684536\n",
      "Current iteration=6600, the loss=27092.970864903087\n",
      "Current iteration=6700, the loss=27088.464486762674\n",
      "Current iteration=6800, the loss=27084.116720736576\n",
      "Current iteration=6900, the loss=27079.92037227011\n",
      "Current iteration=7000, the loss=27075.868668023228\n",
      "Current iteration=7100, the loss=27071.95522521184\n",
      "Current iteration=7200, the loss=27068.174023023996\n",
      "Current iteration=7300, the loss=27064.51937608765\n",
      "Current iteration=7400, the loss=27060.985909956682\n",
      "Current iteration=7500, the loss=27057.568538565756\n",
      "Current iteration=7600, the loss=27054.26244358334\n",
      "Current iteration=7700, the loss=27051.063055571874\n",
      "Current iteration=7800, the loss=27047.96603684497\n",
      "Current iteration=7900, the loss=27044.967265896797\n",
      "Current iteration=8000, the loss=27042.062823269967\n",
      "Current iteration=8100, the loss=27039.24897872399\n",
      "Current iteration=8200, the loss=27036.52217956843\n",
      "Current iteration=8300, the loss=27033.87904003036\n",
      "Current iteration=8400, the loss=27031.316331534712\n",
      "Current iteration=8500, the loss=27028.830973787855\n",
      "Current iteration=8600, the loss=27026.420026566273\n",
      "Current iteration=8700, the loss=27024.08068212504\n",
      "Current iteration=8800, the loss=27021.810258152636\n",
      "Current iteration=8900, the loss=27019.606191209554\n",
      "Current iteration=9000, the loss=27017.466030598007\n",
      "Current iteration=9100, the loss=27015.387432618325\n",
      "Current iteration=9200, the loss=27013.36815517518\n",
      "Current iteration=9300, the loss=27011.406052702238\n",
      "Current iteration=9400, the loss=27009.499071379018\n",
      "Current iteration=9500, the loss=27007.645244617506\n",
      "Current iteration=9600, the loss=27005.84268879918\n",
      "Current iteration=9700, the loss=27004.089599245548\n",
      "Current iteration=9800, the loss=27002.38424640716\n",
      "Current iteration=9900, the loss=27000.72497225783\n",
      "Current iteration=10000, the loss=26999.110186881728\n",
      "Current iteration=10100, the loss=26997.538365242177\n",
      "Current iteration=10200, the loss=26996.008044121747\n",
      "Current iteration=10300, the loss=26994.517819224056\n",
      "Current iteration=10400, the loss=26993.066342426955\n",
      "Current iteration=10500, the loss=26991.65231918566\n",
      "Current iteration=10600, the loss=26990.27450640319\n",
      "Current iteration=10700, the loss=26988.93171309204\n",
      "Current iteration=10800, the loss=26987.62252755468\n",
      "Current iteration=10900, the loss=26986.344761911023\n",
      "Current iteration=11000, the loss=26987.615081624055\n",
      "Current iteration=11100, the loss=26987.90404812168\n",
      "Current iteration=11200, the loss=26980.174510681427\n",
      "Current iteration=11300, the loss=26978.05681448345\n",
      "Current iteration=11400, the loss=26980.93297427035\n",
      "Current iteration=11500, the loss=26974.385900453504\n",
      "Current iteration=11600, the loss=26979.24828478441\n",
      "Current iteration=11700, the loss=26973.583542065586\n",
      "Current iteration=11800, the loss=26977.64212604642\n",
      "Current iteration=11900, the loss=26967.52026066089\n",
      "The loss=27083.85241088885\n",
      "Current iteration=0, the loss=39344.61329025904\n",
      "Current iteration=100, the loss=33933.393424671674\n",
      "Current iteration=200, the loss=32746.07940788655\n",
      "Current iteration=300, the loss=31768.71995569045\n",
      "Current iteration=400, the loss=31117.276835616572\n",
      "Current iteration=500, the loss=30501.6679699575\n",
      "Current iteration=600, the loss=30117.488570783134\n",
      "Current iteration=700, the loss=29746.79722522465\n",
      "Current iteration=800, the loss=29473.272859684013\n",
      "Current iteration=900, the loss=29242.259067802635\n",
      "Current iteration=1000, the loss=29061.09578303419\n",
      "Current iteration=1100, the loss=28905.735354256805\n",
      "Current iteration=1200, the loss=28771.3513969243\n",
      "Current iteration=1300, the loss=28654.00702397739\n",
      "Current iteration=1400, the loss=28550.709881528488\n",
      "Current iteration=1500, the loss=28459.125980991375\n",
      "Current iteration=1600, the loss=28377.400215810867\n",
      "Current iteration=1700, the loss=28304.04058536465\n",
      "Current iteration=1800, the loss=28237.8359430596\n",
      "Current iteration=1900, the loss=28177.795167821518\n",
      "Current iteration=2000, the loss=28123.101762149454\n",
      "Current iteration=2100, the loss=28073.079435793057\n",
      "Current iteration=2200, the loss=28027.165214071832\n",
      "Current iteration=2300, the loss=27984.88773387467\n",
      "Current iteration=2400, the loss=27945.849448066994\n",
      "Current iteration=2500, the loss=27909.712137607807\n",
      "Current iteration=2600, the loss=27876.18535791664\n",
      "Current iteration=2700, the loss=27845.017409858407\n",
      "Current iteration=2800, the loss=27815.988357515555\n",
      "Current iteration=2900, the loss=27788.904623547445\n",
      "Current iteration=3000, the loss=27763.594769359475\n",
      "Current iteration=3100, the loss=27739.906163593645\n",
      "Current iteration=3200, the loss=27717.702324607235\n",
      "Current iteration=3300, the loss=27696.86078052209\n",
      "Current iteration=3400, the loss=27677.27132823837\n",
      "Current iteration=3500, the loss=27658.834598363777\n",
      "Current iteration=3600, the loss=27641.460852416007\n",
      "Current iteration=3700, the loss=27625.068955048413\n",
      "Current iteration=3800, the loss=27609.585478387584\n",
      "Current iteration=3900, the loss=27594.943907806017\n",
      "Current iteration=4000, the loss=27581.083928340664\n",
      "Current iteration=4100, the loss=27567.950778442533\n",
      "Current iteration=4200, the loss=27555.494662973808\n",
      "Current iteration=4300, the loss=27543.67022069034\n",
      "Current iteration=4400, the loss=27532.436043268404\n",
      "Current iteration=4500, the loss=27521.754243665637\n",
      "Current iteration=4600, the loss=27511.5900716239\n",
      "Current iteration=4700, the loss=27501.911573746023\n",
      "Current iteration=4800, the loss=27492.68929505987\n",
      "Current iteration=4900, the loss=27483.896018501488\n",
      "Current iteration=5000, the loss=27475.50653841431\n",
      "Current iteration=5100, the loss=27467.49746402214\n",
      "Current iteration=5200, the loss=27459.847048884098\n",
      "Current iteration=5300, the loss=27452.535041996292\n",
      "Current iteration=5400, the loss=27445.542430521495\n",
      "Current iteration=5500, the loss=27438.788805206168\n",
      "Current iteration=5600, the loss=27385.109379793277\n",
      "Current iteration=5700, the loss=27349.796765973355\n",
      "Current iteration=5800, the loss=27342.319161389194\n",
      "Current iteration=5900, the loss=27335.618954466878\n",
      "Current iteration=6000, the loss=27329.331201395384\n",
      "Current iteration=6100, the loss=27323.36499212044\n",
      "Current iteration=6200, the loss=27317.67922952887\n",
      "Current iteration=6300, the loss=27312.247130705095\n",
      "Current iteration=6400, the loss=27307.04837178313\n",
      "Current iteration=6500, the loss=27302.066374713955\n",
      "Current iteration=6600, the loss=27297.287035856825\n",
      "Current iteration=6700, the loss=27292.698028634033\n",
      "Current iteration=6800, the loss=27288.28838189847\n",
      "Current iteration=6900, the loss=27284.048204769228\n",
      "Current iteration=7000, the loss=27279.968495348174\n",
      "Current iteration=7100, the loss=27276.04100084235\n",
      "Current iteration=7200, the loss=27272.25811118168\n",
      "Current iteration=7300, the loss=27268.6127756362\n",
      "Current iteration=7400, the loss=27265.098435910793\n",
      "Current iteration=7500, the loss=27261.708971444736\n",
      "Current iteration=7600, the loss=27258.438653989648\n",
      "Current iteration=7700, the loss=27255.28210938732\n",
      "Current iteration=7800, the loss=27252.234285029794\n",
      "Current iteration=7900, the loss=27249.29042186761\n",
      "Current iteration=8000, the loss=27246.446030104402\n",
      "Current iteration=8100, the loss=27243.696867912346\n",
      "Current iteration=8200, the loss=27241.038922648888\n",
      "Current iteration=8300, the loss=27238.468394164163\n",
      "Current iteration=8400, the loss=27235.981679871435\n",
      "Current iteration=8500, the loss=27233.575361317227\n",
      "Current iteration=8600, the loss=27231.24619203684\n",
      "Current iteration=8700, the loss=27228.991086520426\n",
      "Current iteration=8800, the loss=27226.807110145015\n",
      "Current iteration=8900, the loss=27224.691469952777\n",
      "Current iteration=9000, the loss=27222.641506175307\n",
      "Current iteration=9100, the loss=27220.65468441925\n",
      "Current iteration=9200, the loss=27218.728588441838\n",
      "Current iteration=9300, the loss=27216.86091345532\n",
      "Current iteration=9400, the loss=27215.049459907506\n",
      "Current iteration=9500, the loss=27213.292127693367\n",
      "Current iteration=9600, the loss=27211.586910758033\n",
      "Current iteration=9700, the loss=27209.93189205673\n",
      "Current iteration=9800, the loss=27208.32523884127\n",
      "Current iteration=9900, the loss=27206.76519824617\n",
      "Current iteration=10000, the loss=27205.250093150586\n",
      "Current iteration=10100, the loss=27203.77831829455\n",
      "Current iteration=10200, the loss=27202.348336630384\n",
      "Current iteration=10300, the loss=27200.958675892012\n",
      "Current iteration=10400, the loss=27199.607925366334\n",
      "Current iteration=10500, the loss=27198.294732852606\n",
      "Current iteration=10600, the loss=27197.01780179656\n",
      "Current iteration=10700, the loss=27195.775888587705\n",
      "Current iteration=10800, the loss=27194.567800008583\n",
      "Current iteration=10900, the loss=27193.392390826026\n",
      "Current iteration=11000, the loss=27192.248561515302\n",
      "Current iteration=11100, the loss=27191.135256108544\n",
      "Current iteration=11200, the loss=27190.051460159397\n",
      "Current iteration=11300, the loss=27188.99619881687\n",
      "Current iteration=11400, the loss=27187.96853500144\n",
      "Current iteration=11500, the loss=27186.96756767718\n",
      "Current iteration=11600, the loss=27185.99243021396\n",
      "Current iteration=11700, the loss=27185.042288834615\n",
      "Current iteration=11800, the loss=27184.116341141642\n",
      "Current iteration=11900, the loss=27183.213814719067\n",
      "The loss=27143.885722917144\n",
      "Current iteration=0, the loss=39234.55146366222\n",
      "Current iteration=100, the loss=33563.186622040645\n",
      "Current iteration=200, the loss=32239.495395402337\n",
      "Current iteration=300, the loss=31324.14053918339\n",
      "Current iteration=400, the loss=30595.30058493001\n",
      "Current iteration=500, the loss=30088.50542427523\n",
      "Current iteration=600, the loss=29689.934407404267\n",
      "Current iteration=700, the loss=29366.406892395207\n",
      "Current iteration=800, the loss=29102.092118788914\n",
      "Current iteration=900, the loss=28882.30672478237\n",
      "Current iteration=1000, the loss=28696.515460578805\n",
      "Current iteration=1100, the loss=28537.31495978588\n",
      "Current iteration=1200, the loss=28399.400464747647\n",
      "Current iteration=1300, the loss=28278.817440366405\n",
      "Current iteration=1400, the loss=28172.54530546662\n",
      "Current iteration=1500, the loss=28078.233458543436\n",
      "Current iteration=1600, the loss=27994.02123588245\n",
      "Current iteration=1700, the loss=27918.414838760298\n",
      "Current iteration=1800, the loss=27850.199979854755\n",
      "Current iteration=1900, the loss=27788.378759006744\n",
      "Current iteration=2000, the loss=27732.12333625026\n",
      "Current iteration=2100, the loss=27680.741374689962\n",
      "Current iteration=2200, the loss=27633.649791541357\n",
      "Current iteration=2300, the loss=27590.35443181332\n",
      "Current iteration=2400, the loss=27550.434029958073\n",
      "Current iteration=2500, the loss=27513.527359783708\n",
      "Current iteration=2600, the loss=27479.32287335734\n",
      "Current iteration=2700, the loss=27447.549804964663\n",
      "Current iteration=2800, the loss=27417.96169198404\n",
      "Current iteration=2900, the loss=27390.318760519018\n",
      "Current iteration=3000, the loss=27364.42019616805\n",
      "Current iteration=3100, the loss=27340.100778110005\n",
      "Current iteration=3200, the loss=27317.217456880837\n",
      "Current iteration=3300, the loss=27295.646648388167\n",
      "Current iteration=3400, the loss=27275.31492201138\n",
      "Current iteration=3500, the loss=27256.430981258418\n",
      "Current iteration=3600, the loss=27238.49444430282\n",
      "Current iteration=3700, the loss=27221.507732865964\n",
      "Current iteration=3800, the loss=27205.44581329121\n",
      "Current iteration=3900, the loss=27190.250436872437\n",
      "Current iteration=4000, the loss=27175.865731109086\n",
      "Current iteration=4100, the loss=27162.237827269222\n",
      "Current iteration=4200, the loss=27149.316000323874\n",
      "Current iteration=4300, the loss=27137.053172962267\n",
      "Current iteration=4400, the loss=27125.405933870978\n",
      "Current iteration=4500, the loss=27114.334338176483\n",
      "Current iteration=4600, the loss=27103.80163348948\n",
      "Current iteration=4700, the loss=27093.773975265955\n",
      "Current iteration=4800, the loss=27084.22015694464\n",
      "Current iteration=4900, the loss=27075.111363418255\n",
      "Current iteration=5000, the loss=27066.42094929821\n",
      "Current iteration=5100, the loss=27058.12424065639\n",
      "Current iteration=5200, the loss=27050.19835800774\n",
      "Current iteration=5300, the loss=27042.622058144705\n",
      "Current iteration=5400, the loss=27035.37559257818\n",
      "Current iteration=5500, the loss=27028.440580577426\n",
      "Current iteration=5600, the loss=27021.799895052915\n",
      "Current iteration=5700, the loss=27015.4375597584\n",
      "Current iteration=5800, the loss=27009.33865649326\n",
      "Current iteration=5900, the loss=27003.489241163592\n",
      "Current iteration=6000, the loss=26997.876267710653\n",
      "Current iteration=6100, the loss=26992.487519044233\n",
      "Current iteration=6200, the loss=26987.31154422818\n",
      "Current iteration=6300, the loss=26982.337601259034\n",
      "Current iteration=6400, the loss=26977.555604858913\n",
      "Current iteration=6500, the loss=26972.95607877287\n",
      "Current iteration=6600, the loss=26968.53011212093\n",
      "Current iteration=6700, the loss=26964.269319406234\n",
      "Current iteration=6800, the loss=26960.165803825777\n",
      "Current iteration=6900, the loss=26956.212123569447\n",
      "Current iteration=7000, the loss=26952.401260826984\n",
      "Current iteration=7100, the loss=26948.726593252723\n",
      "Current iteration=7200, the loss=26945.181867664076\n",
      "Current iteration=7300, the loss=26941.761175773187\n",
      "Current iteration=7400, the loss=26938.458931771296\n",
      "Current iteration=7500, the loss=26935.269851603873\n",
      "Current iteration=7600, the loss=26932.188933790367\n",
      "Current iteration=7700, the loss=26929.21144165686\n",
      "Current iteration=7800, the loss=26926.33288686262\n",
      "Current iteration=7900, the loss=26923.549014112737\n",
      "Current iteration=8000, the loss=26920.855786959393\n",
      "Current iteration=8100, the loss=26918.24937460315\n",
      "Current iteration=8200, the loss=26915.72613961397\n",
      "Current iteration=8300, the loss=26913.282626498873\n",
      "Current iteration=8400, the loss=26910.91555104944\n",
      "Current iteration=8500, the loss=26908.621790409044\n",
      "Current iteration=8600, the loss=26906.398373803793\n",
      "Current iteration=8700, the loss=26904.242473887287\n",
      "Current iteration=8800, the loss=26902.151398652473\n",
      "Current iteration=8900, the loss=26900.12258386868\n",
      "Current iteration=9000, the loss=26898.153586004857\n",
      "Current iteration=9100, the loss=26896.242075603524\n",
      "Current iteration=9200, the loss=26894.385831072934\n",
      "Current iteration=9300, the loss=26892.582732867446\n",
      "Current iteration=9400, the loss=26890.83075802836\n",
      "Current iteration=9500, the loss=26889.12797506026\n",
      "Current iteration=9600, the loss=26887.472539119084\n",
      "Current iteration=9700, the loss=26885.862687490815\n",
      "Current iteration=9800, the loss=26884.29673534046\n",
      "Current iteration=9900, the loss=26882.773071713567\n",
      "Current iteration=10000, the loss=26881.290155772687\n",
      "Current iteration=10100, the loss=26879.84651325372\n",
      "Current iteration=10200, the loss=26878.44073312714\n",
      "Current iteration=10300, the loss=26877.071464451157\n",
      "Current iteration=10400, the loss=26875.737413403836\n",
      "Current iteration=10500, the loss=26874.43734048319\n",
      "Current iteration=10600, the loss=26873.170057864096\n",
      "Current iteration=10700, the loss=26871.934426902284\n",
      "Current iteration=10800, the loss=26870.729355776275\n",
      "Current iteration=10900, the loss=26869.553797258362\n",
      "Current iteration=11000, the loss=26868.40674660696\n",
      "Current iteration=11100, the loss=26867.287239572725\n",
      "Current iteration=11200, the loss=26866.19435051147\n",
      "Current iteration=11300, the loss=26865.127190597555\n",
      "Current iteration=11400, the loss=26864.08490613167\n",
      "Current iteration=11500, the loss=26863.066676937335\n",
      "Current iteration=11600, the loss=26862.071714840935\n",
      "Current iteration=11700, the loss=26861.099262230324\n",
      "Current iteration=11800, the loss=26860.14859068763\n",
      "Current iteration=11900, the loss=26859.218999691526\n",
      "The loss=26839.410173384804\n",
      "Training error: 27005.612549821315\n",
      "Test error: 9069.971225050314\n",
      "Classification accuracy: 0.7873207469307748\n"
     ]
    }
   ],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_1 = 12000\n",
    "gamma_1 = 1e-7\n",
    "lambda_1 = 0\n",
    "degree_1 = 3\n",
    "batch_size1 = 100\n",
    "k = 4\n",
    "current_y = y1\n",
    "current_X = X1\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly(test_x, degree_1)\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly(training_x, degree_1)\n",
    "\n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_1, gamma_1, max_iters_1)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=17029.074232293548\n",
      "Current iteration=100, the loss=12857.640260643777\n",
      "Current iteration=200, the loss=12290.531448393613\n",
      "Current iteration=300, the loss=11977.920522161216\n",
      "Current iteration=400, the loss=11768.22536106244\n",
      "Current iteration=500, the loss=11617.056287885822\n",
      "Current iteration=600, the loss=11503.492068653803\n",
      "Current iteration=700, the loss=11415.749822105838\n",
      "Current iteration=800, the loss=11346.547002092879\n",
      "Current iteration=900, the loss=11291.09383232849\n",
      "Current iteration=1000, the loss=11246.092335861133\n",
      "Current iteration=1100, the loss=11209.190944059956\n",
      "Current iteration=1200, the loss=11178.666323994246\n",
      "Current iteration=1300, the loss=11153.227300958104\n",
      "Current iteration=1400, the loss=11131.88863435428\n",
      "Current iteration=1500, the loss=11113.886863402193\n",
      "Current iteration=1600, the loss=11098.62255934523\n",
      "Current iteration=1700, the loss=11085.619721414074\n",
      "Current iteration=1800, the loss=11074.496621884617\n",
      "Current iteration=1900, the loss=11064.944484833573\n",
      "Current iteration=2000, the loss=11056.711639771962\n",
      "Current iteration=2100, the loss=11049.59157423277\n",
      "Current iteration=2200, the loss=11043.413810094924\n",
      "Current iteration=2300, the loss=11038.036856099377\n",
      "Current iteration=2400, the loss=11033.342707897704\n",
      "Current iteration=2500, the loss=11029.232515930093\n",
      "Current iteration=2600, the loss=11025.623144532063\n",
      "Current iteration=2700, the loss=11022.444418151848\n",
      "Current iteration=2800, the loss=11019.636902252969\n",
      "Current iteration=2900, the loss=11017.150103833028\n",
      "Current iteration=3000, the loss=11014.941003818236\n",
      "Current iteration=3100, the loss=11012.972853813546\n",
      "Current iteration=3200, the loss=11011.214184805984\n",
      "Current iteration=3300, the loss=11009.637986833666\n",
      "Current iteration=3400, the loss=11008.221027327563\n",
      "Current iteration=3500, the loss=11006.943282513763\n",
      "Current iteration=3600, the loss=11005.787461435375\n",
      "Current iteration=3700, the loss=11004.738606186667\n",
      "Current iteration=3800, the loss=11003.783755118344\n",
      "Current iteration=3900, the loss=11002.91165827473\n",
      "Current iteration=4000, the loss=11002.112536312019\n",
      "Current iteration=4100, the loss=11001.377875735183\n",
      "Current iteration=4200, the loss=11000.70025456796\n",
      "Current iteration=4300, the loss=11000.073193599826\n",
      "Current iteration=4400, the loss=10999.49102918962\n",
      "Current iteration=4500, the loss=10998.94880428529\n",
      "Current iteration=4600, the loss=10998.442174875661\n",
      "Current iteration=4700, the loss=10997.96732954619\n",
      "Current iteration=4800, the loss=10997.520920187017\n",
      "Current iteration=4900, the loss=10997.100002212126\n",
      "Current iteration=5000, the loss=10996.701982906376\n",
      "Current iteration=5100, the loss=10996.324576731226\n",
      "Current iteration=5200, the loss=10995.965766599104\n",
      "Current iteration=5300, the loss=10995.62377027588\n",
      "Current iteration=5400, the loss=10995.297011196315\n",
      "Current iteration=5500, the loss=10994.984093083054\n",
      "Current iteration=5600, the loss=10994.683777848673\n",
      "Current iteration=5700, the loss=10994.394966335323\n",
      "Current iteration=5800, the loss=10994.116681510422\n",
      "Current iteration=5900, the loss=10993.848053790662\n",
      "Current iteration=6000, the loss=10993.588308212584\n",
      "Current iteration=6100, the loss=10993.336753207299\n",
      "Current iteration=6200, the loss=10993.092770769908\n",
      "Current iteration=6300, the loss=10992.855807843218\n",
      "Current iteration=6400, the loss=10992.625368759494\n",
      "Current iteration=6500, the loss=10992.401008605037\n",
      "Current iteration=6600, the loss=10992.18232739038\n",
      "Current iteration=6700, the loss=10991.968964924577\n",
      "Current iteration=6800, the loss=10991.760596305096\n",
      "Current iteration=6900, the loss=10991.55692794656\n",
      "Current iteration=7000, the loss=10991.35769408161\n",
      "Current iteration=7100, the loss=10991.162653675503\n",
      "Current iteration=7200, the loss=10990.971587703763\n",
      "Current iteration=7300, the loss=10990.784296748501\n",
      "Current iteration=7400, the loss=10990.600598874731\n",
      "Current iteration=7500, the loss=10990.420327752789\n",
      "Current iteration=7600, the loss=10990.243330997306\n",
      "Current iteration=7700, the loss=10990.069468696682\n",
      "Current iteration=7800, the loss=10989.898612110512\n",
      "Current iteration=7900, the loss=10989.730642514827\n",
      "Current iteration=8000, the loss=10989.565450177903\n",
      "Current iteration=8100, the loss=10989.40293345107\n",
      "Current iteration=8200, the loss=10989.242997961199\n",
      "Current iteration=8300, the loss=10989.085555892852\n",
      "Current iteration=8400, the loss=10988.930525349853\n",
      "Current iteration=8500, the loss=10988.777829786952\n",
      "Current iteration=8600, the loss=10988.627397503547\n",
      "Current iteration=8700, the loss=10988.479161192317\n",
      "Current iteration=8800, the loss=10988.333057536576\n",
      "Current iteration=8900, the loss=10988.189026850687\n",
      "Current iteration=9000, the loss=10988.047012758678\n",
      "Current iteration=9100, the loss=10987.906961906829\n",
      "Current iteration=9200, the loss=10987.768823706323\n",
      "Current iteration=9300, the loss=10987.632550102597\n",
      "Current iteration=9400, the loss=10987.498095368468\n",
      "Current iteration=9500, the loss=10987.365415918335\n",
      "Current iteration=9600, the loss=10987.234470141218\n",
      "Current iteration=9700, the loss=10987.105218250403\n",
      "Current iteration=9800, the loss=10986.977622148042\n",
      "Current iteration=9900, the loss=10986.851645303006\n",
      "Current iteration=10000, the loss=10986.7272526405\n",
      "Current iteration=10100, the loss=10986.60441044225\n",
      "Current iteration=10200, the loss=10986.483086256132\n",
      "Current iteration=10300, the loss=10986.36324881417\n",
      "Current iteration=10400, the loss=10986.244867958038\n",
      "Current iteration=10500, the loss=10986.127914571309\n",
      "Current iteration=10600, the loss=10986.012360517714\n",
      "Current iteration=10700, the loss=10985.898178584768\n",
      "Current iteration=10800, the loss=10985.785342432264\n",
      "Current iteration=10900, the loss=10985.673826545106\n",
      "Current iteration=11000, the loss=10985.563606189946\n",
      "Current iteration=11100, the loss=10985.454657375441\n",
      "Current iteration=11200, the loss=10985.346956815629\n",
      "Current iteration=11300, the loss=10985.240481896064\n",
      "Current iteration=11400, the loss=10985.135210642606\n",
      "Current iteration=11500, the loss=10985.031121692471\n",
      "Current iteration=11600, the loss=10984.928194267384\n",
      "Current iteration=11700, the loss=10984.826408148598\n",
      "Current iteration=11800, the loss=10984.72574365365\n",
      "Current iteration=11900, the loss=10984.62618161468\n",
      "The loss=10984.528682836051\n",
      "Current iteration=0, the loss=17060.86031452528\n",
      "Current iteration=100, the loss=12956.758355193182\n",
      "Current iteration=200, the loss=12375.192503440883\n",
      "Current iteration=300, the loss=12050.045365324815\n",
      "Current iteration=400, the loss=11831.104421288886\n",
      "Current iteration=500, the loss=11673.240960060044\n",
      "Current iteration=600, the loss=11554.771462692817\n",
      "Current iteration=700, the loss=11463.332146455952\n",
      "Current iteration=800, the loss=11391.244085617222\n",
      "Current iteration=900, the loss=11333.459948878346\n",
      "Current iteration=1000, the loss=11286.517666653432\n",
      "Current iteration=1100, the loss=11247.960937011056\n",
      "Current iteration=1200, the loss=11215.998411786377\n",
      "Current iteration=1300, the loss=11189.293516087411\n",
      "Current iteration=1400, the loss=11166.82966545557\n",
      "Current iteration=1500, the loss=11147.82093835662\n",
      "Current iteration=1600, the loss=11131.651178243046\n",
      "Current iteration=1700, the loss=11117.83144693972\n",
      "Current iteration=1800, the loss=11105.969654216347\n",
      "Current iteration=1900, the loss=11095.748464424672\n",
      "Current iteration=2000, the loss=11086.908952020654\n",
      "Current iteration=2100, the loss=11079.238327518207\n",
      "Current iteration=2200, the loss=11072.56059568344\n",
      "Current iteration=2300, the loss=11066.729359238052\n",
      "Current iteration=2400, the loss=11061.622214760213\n",
      "Current iteration=2500, the loss=11057.136345441602\n",
      "Current iteration=2600, the loss=11053.185024118935\n",
      "Current iteration=2700, the loss=11049.694816066662\n",
      "Current iteration=2800, the loss=11046.603325016378\n",
      "Current iteration=2900, the loss=11043.857364689346\n",
      "Current iteration=3000, the loss=11041.4114663957\n",
      "Current iteration=3100, the loss=11039.226654076137\n",
      "Current iteration=3200, the loss=11037.26943366482\n",
      "Current iteration=3300, the loss=11035.510955311955\n",
      "Current iteration=3400, the loss=11033.926315855424\n",
      "Current iteration=3500, the loss=11032.493975709476\n",
      "Current iteration=3600, the loss=11031.195269572094\n",
      "Current iteration=3700, the loss=11030.013994424691\n",
      "Current iteration=3800, the loss=11028.936061488683\n",
      "Current iteration=3900, the loss=11027.949201320993\n",
      "Current iteration=4000, the loss=11027.042713228642\n",
      "Current iteration=4100, the loss=11026.207251778622\n",
      "Current iteration=4200, the loss=11025.434644460089\n",
      "Current iteration=4300, the loss=11024.71773559037\n",
      "Current iteration=4400, the loss=11024.050252394474\n",
      "Current iteration=4500, the loss=11023.426689871209\n",
      "Current iteration=4600, the loss=11022.842211617794\n",
      "Current iteration=4700, the loss=11022.29256424401\n",
      "Current iteration=4800, the loss=11021.774003385603\n",
      "Current iteration=4900, the loss=11021.283229639848\n",
      "Current iteration=5000, the loss=11020.817333006496\n",
      "Current iteration=5100, the loss=11020.37374463393\n",
      "Current iteration=5200, the loss=11019.950194851524\n",
      "Current iteration=5300, the loss=11019.54467662096\n",
      "Current iteration=5400, the loss=11019.155413666776\n",
      "Current iteration=5500, the loss=11018.780832654022\n",
      "Current iteration=5600, the loss=11018.419538871392\n",
      "Current iteration=5700, the loss=11018.070294955374\n",
      "Current iteration=5800, the loss=11017.732002255896\n",
      "Current iteration=5900, the loss=11017.403684499783\n",
      "Current iteration=6000, the loss=11017.084473455183\n",
      "Current iteration=6100, the loss=11016.773596340765\n",
      "Current iteration=6200, the loss=11016.470364758166\n",
      "Current iteration=6300, the loss=11016.174164955333\n",
      "Current iteration=6400, the loss=11015.884449254336\n",
      "Current iteration=6500, the loss=11015.600728498674\n",
      "Current iteration=6600, the loss=11015.32256539437\n",
      "Current iteration=6700, the loss=11015.049568634888\n",
      "Current iteration=6800, the loss=11014.781387714505\n",
      "Current iteration=6900, the loss=11014.517708346546\n",
      "Current iteration=7000, the loss=11014.258248413513\n",
      "Current iteration=7100, the loss=11014.002754385445\n",
      "Current iteration=7200, the loss=11013.750998150543\n",
      "Current iteration=7300, the loss=11013.502774209184\n",
      "Current iteration=7400, the loss=11013.257897188447\n",
      "Current iteration=7500, the loss=11013.01619963935\n",
      "Current iteration=7600, the loss=11012.777530083822\n",
      "Current iteration=7700, the loss=11012.541751282275\n",
      "Current iteration=7800, the loss=11012.308738696203\n",
      "Current iteration=7900, the loss=11012.078379123137\n",
      "Current iteration=8000, the loss=11011.850569484337\n",
      "Current iteration=8100, the loss=11011.6252157475\n",
      "Current iteration=8200, the loss=11011.402231969147\n",
      "Current iteration=8300, the loss=11011.181539443045\n",
      "Current iteration=8400, the loss=11010.963065942666\n",
      "Current iteration=8500, the loss=11010.746745046883\n",
      "Current iteration=8600, the loss=11010.532515539784\n",
      "Current iteration=8700, the loss=11010.320320876006\n",
      "Current iteration=8800, the loss=11010.11010870436\n",
      "Current iteration=8900, the loss=11009.901830443323\n",
      "Current iteration=9000, the loss=11009.695440902375\n",
      "Current iteration=9100, the loss=11009.490897944324\n",
      "Current iteration=9200, the loss=11009.288162183973\n",
      "Current iteration=9300, the loss=11009.087196719029\n",
      "Current iteration=9400, the loss=11008.887966889826\n",
      "Current iteration=9500, the loss=11008.690440064718\n",
      "Current iteration=9600, the loss=11008.494585448108\n",
      "Current iteration=9700, the loss=11008.300373908853\n",
      "Current iteration=9800, the loss=11008.10777782679\n",
      "Current iteration=9900, the loss=11007.916770955242\n",
      "Current iteration=10000, the loss=11007.727328297973\n",
      "Current iteration=10100, the loss=11007.539425998915\n",
      "Current iteration=10200, the loss=11007.353041243296\n",
      "Current iteration=10300, the loss=11007.16815216895\n",
      "Current iteration=10400, the loss=11006.984737786708\n",
      "Current iteration=10500, the loss=11006.802777908932\n",
      "Current iteration=10600, the loss=11006.622253085228\n",
      "Current iteration=10700, the loss=11006.443144544672\n",
      "Current iteration=10800, the loss=11006.265434143806\n",
      "Current iteration=10900, the loss=11006.089104319755\n",
      "Current iteration=11000, the loss=11005.914138048029\n",
      "Current iteration=11100, the loss=11005.740518804363\n",
      "Current iteration=11200, the loss=11005.568230530349\n",
      "Current iteration=11300, the loss=11005.397257602312\n",
      "Current iteration=11400, the loss=11005.22758480311\n",
      "Current iteration=11500, the loss=11005.05919729668\n",
      "Current iteration=11600, the loss=11004.892080604852\n",
      "Current iteration=11700, the loss=11004.726220586414\n",
      "Current iteration=11800, the loss=11004.561603417915\n",
      "Current iteration=11900, the loss=11004.398215576373\n",
      "The loss=11004.237659564045\n",
      "Training error: 10994.383171200048\n",
      "Test error: 11056.756832711473\n",
      "Classification accuracy: 0.8061256897852237\n"
     ]
    }
   ],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_2 = 12000\n",
    "gamma_2 = 1e-6\n",
    "lambda_2 = 0.0\n",
    "degree_2 = 2\n",
    "batch_size2 = 100\n",
    "k = 2\n",
    "current_y = y2\n",
    "current_X = X2\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly(test_x, degree_2)\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly(training_x, degree_2)\n",
    "    \n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_2, gamma_2, max_iters_2)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=7263.42224758955\n",
      "Current iteration=100, the loss=6048.835832145423\n",
      "Current iteration=200, the loss=5896.717748681341\n",
      "Current iteration=300, the loss=5760.360737329438\n",
      "Current iteration=400, the loss=5675.60681034956\n",
      "Current iteration=500, the loss=5608.947593023511\n",
      "Current iteration=600, the loss=5538.4055733654\n",
      "Current iteration=700, the loss=5479.672266947327\n",
      "Current iteration=800, the loss=5445.250065851807\n",
      "Current iteration=900, the loss=5400.945775770389\n",
      "Current iteration=1000, the loss=5358.6704474901635\n",
      "Current iteration=1100, the loss=5329.941929169332\n",
      "Current iteration=1200, the loss=5306.425869978817\n",
      "Current iteration=1300, the loss=5276.600837577902\n",
      "Current iteration=1400, the loss=5269.784719560236\n",
      "Current iteration=1500, the loss=5239.125540447688\n",
      "Current iteration=1600, the loss=5237.472083371727\n",
      "Current iteration=1700, the loss=5198.917012250523\n",
      "Current iteration=1800, the loss=5199.71178160437\n",
      "Current iteration=1900, the loss=5174.988139311583\n",
      "Current iteration=2000, the loss=5164.928204236129\n",
      "Current iteration=2100, the loss=5160.376417821179\n",
      "Current iteration=2200, the loss=5137.829889620819\n",
      "Current iteration=2300, the loss=5133.4810201150285\n",
      "Current iteration=2400, the loss=5118.548278849842\n",
      "Current iteration=2500, the loss=5122.015043259926\n",
      "Current iteration=2600, the loss=5104.55226006553\n",
      "Current iteration=2700, the loss=5107.3088842900015\n",
      "Current iteration=2800, the loss=5086.783696759702\n",
      "Current iteration=2900, the loss=5084.66891794904\n",
      "Current iteration=3000, the loss=5074.233574118686\n",
      "Current iteration=3100, the loss=5072.403046878542\n",
      "Current iteration=3200, the loss=5077.5274995738255\n",
      "Current iteration=3300, the loss=5058.391991385099\n",
      "Current iteration=3400, the loss=5065.759467367974\n",
      "Current iteration=3500, the loss=5045.957474214986\n",
      "Current iteration=3600, the loss=5044.842841798428\n",
      "Current iteration=3700, the loss=5053.200777004841\n",
      "Current iteration=3800, the loss=5043.4376729932\n",
      "Current iteration=3900, the loss=5046.683364234182\n",
      "Current iteration=4000, the loss=5041.774953514176\n",
      "Current iteration=4100, the loss=5039.595098419645\n",
      "Current iteration=4200, the loss=5035.422347651122\n",
      "Current iteration=4300, the loss=5023.848285548757\n",
      "Current iteration=4400, the loss=5035.414053411226\n",
      "Current iteration=4500, the loss=5020.4903927567175\n",
      "Current iteration=4600, the loss=5018.092316037022\n",
      "Current iteration=4700, the loss=5007.521643126863\n",
      "Current iteration=4800, the loss=5005.473329761447\n",
      "Current iteration=4900, the loss=5011.764497240128\n",
      "Current iteration=5000, the loss=5005.3226120642485\n",
      "Current iteration=5100, the loss=5010.753270162671\n",
      "Current iteration=5200, the loss=5020.988067704937\n",
      "Current iteration=5300, the loss=5018.571513456185\n",
      "Current iteration=5400, the loss=5003.203375341985\n",
      "Current iteration=5500, the loss=4998.173417664085\n",
      "Current iteration=5600, the loss=5001.879326277965\n",
      "Current iteration=5700, the loss=5014.077077180738\n",
      "Current iteration=5800, the loss=5009.953947290188\n",
      "Current iteration=5900, the loss=5008.746807255338\n",
      "Current iteration=6000, the loss=4996.533518341402\n",
      "Current iteration=6100, the loss=4995.250811429583\n",
      "Current iteration=6200, the loss=4994.207422510539\n",
      "Current iteration=6300, the loss=4993.235439304216\n",
      "Current iteration=6400, the loss=4992.309267868821\n",
      "Current iteration=6500, the loss=4991.42453503914\n",
      "Current iteration=6600, the loss=4990.5838631365505\n",
      "Current iteration=6700, the loss=4989.790602734104\n",
      "Current iteration=6800, the loss=4989.047899222111\n",
      "Current iteration=6900, the loss=4988.348814381258\n",
      "Current iteration=7000, the loss=4987.658137537205\n",
      "Current iteration=7100, the loss=4986.9535328244665\n",
      "Current iteration=7200, the loss=4986.259034086302\n",
      "Current iteration=7300, the loss=4985.589191007831\n",
      "Current iteration=7400, the loss=4984.944907176763\n",
      "Current iteration=7500, the loss=4984.325059449291\n",
      "Current iteration=7600, the loss=4983.7285057961635\n",
      "Current iteration=7700, the loss=4983.154173542197\n",
      "Current iteration=7800, the loss=4982.601056115686\n",
      "Current iteration=7900, the loss=4982.068208716362\n",
      "Current iteration=8000, the loss=4981.554744147417\n",
      "Current iteration=8100, the loss=4981.059828735828\n",
      "Current iteration=8200, the loss=4980.582678254719\n",
      "Current iteration=8300, the loss=4980.122553749963\n",
      "Current iteration=8400, the loss=4979.678757158316\n",
      "Current iteration=8500, the loss=4979.250626588722\n",
      "Current iteration=8600, the loss=4978.837531126056\n",
      "Current iteration=8700, the loss=4978.438865013566\n",
      "Current iteration=8800, the loss=4978.054041086897\n",
      "Current iteration=8900, the loss=4977.682483383215\n",
      "Current iteration=9000, the loss=4977.323618952933\n",
      "Current iteration=9100, the loss=4976.976869079466\n",
      "Current iteration=9200, the loss=4976.6416403793255\n",
      "Current iteration=9300, the loss=4976.317316604411\n",
      "Current iteration=9400, the loss=4976.003252352287\n",
      "Current iteration=9500, the loss=4975.698770197287\n",
      "Current iteration=9600, the loss=4975.403162809612\n",
      "Current iteration=9700, the loss=4975.115701235049\n",
      "Current iteration=9800, the loss=4974.835649552694\n",
      "Current iteration=9900, the loss=4974.562284719395\n",
      "Current iteration=10000, the loss=4974.294918944646\n",
      "Current iteration=10100, the loss=4974.032920998961\n",
      "Current iteration=10200, the loss=4973.775732915131\n",
      "Current iteration=10300, the loss=4973.5228796516985\n",
      "Current iteration=10400, the loss=4973.2739710171645\n",
      "Current iteration=10500, the loss=4973.028696822204\n",
      "Current iteration=10600, the loss=4972.786817291605\n",
      "Current iteration=10700, the loss=4972.548151055457\n",
      "Current iteration=10800, the loss=4972.312562717307\n",
      "Current iteration=10900, the loss=4972.079951379179\n",
      "Current iteration=11000, the loss=4971.850240865544\n",
      "Current iteration=11100, the loss=4971.623371886196\n",
      "Current iteration=11200, the loss=4971.399296055585\n",
      "Current iteration=11300, the loss=4971.177971520061\n",
      "Current iteration=11400, the loss=4970.9593598878855\n",
      "Current iteration=11500, the loss=4970.743424164839\n",
      "Current iteration=11600, the loss=4970.530127436867\n",
      "Current iteration=11700, the loss=4970.319432090062\n",
      "Current iteration=11800, the loss=4970.111299405534\n",
      "Current iteration=11900, the loss=4969.905689407648\n",
      "The loss=4970.370952147731\n",
      "Current iteration=0, the loss=7187.209452989748\n",
      "Current iteration=100, the loss=5966.8693270799795\n",
      "Current iteration=200, the loss=5800.084074129843\n",
      "Current iteration=300, the loss=5687.832087503415\n",
      "Current iteration=400, the loss=5595.8840315081925\n",
      "Current iteration=500, the loss=5530.330732900213\n",
      "Current iteration=600, the loss=5463.029726571491\n",
      "Current iteration=700, the loss=5417.095887049193\n",
      "Current iteration=800, the loss=5370.659001112798\n",
      "Current iteration=900, the loss=5328.596377735126\n",
      "Current iteration=1000, the loss=5295.611152369808\n",
      "Current iteration=1100, the loss=5259.5818448759965\n",
      "Current iteration=1200, the loss=5233.980549493549\n",
      "Current iteration=1300, the loss=5214.226672679988\n",
      "Current iteration=1400, the loss=5195.228741162331\n",
      "Current iteration=1500, the loss=5165.672889198324\n",
      "Current iteration=1600, the loss=5155.905290840115\n",
      "Current iteration=1700, the loss=5143.570276248052\n",
      "Current iteration=1800, the loss=5126.625900521035\n",
      "Current iteration=1900, the loss=5105.024084517942\n",
      "Current iteration=2000, the loss=5102.0674584703775\n",
      "Current iteration=2100, the loss=5075.445095207493\n",
      "Current iteration=2200, the loss=5067.588084078251\n",
      "Current iteration=2300, the loss=5058.3369999198085\n",
      "Current iteration=2400, the loss=5050.9643105025925\n",
      "Current iteration=2500, the loss=5045.279169218646\n",
      "Current iteration=2600, the loss=5037.895610529161\n",
      "Current iteration=2700, the loss=5035.074442570528\n",
      "Current iteration=2800, the loss=5014.381973001184\n",
      "Current iteration=2900, the loss=5010.886702090892\n",
      "Current iteration=3000, the loss=5003.122713363779\n",
      "Current iteration=3100, the loss=4999.308493237183\n",
      "Current iteration=3200, the loss=4994.226861317241\n",
      "Current iteration=3300, the loss=4999.173146316849\n",
      "Current iteration=3400, the loss=4986.176046736811\n",
      "Current iteration=3500, the loss=4985.353273192834\n",
      "Current iteration=3600, the loss=4983.046088759501\n",
      "Current iteration=3700, the loss=4971.925913219764\n",
      "Current iteration=3800, the loss=4972.445276141008\n",
      "Current iteration=3900, the loss=4963.990898489773\n",
      "Current iteration=4000, the loss=4976.944300887068\n",
      "Current iteration=4100, the loss=4966.104817697152\n",
      "Current iteration=4200, the loss=4959.570916845623\n",
      "Current iteration=4300, the loss=4952.31853816481\n",
      "Current iteration=4400, the loss=4964.909495899613\n",
      "Current iteration=4500, the loss=4955.880699478321\n",
      "Current iteration=4600, the loss=4948.934840742795\n",
      "Current iteration=4700, the loss=4942.230284894093\n",
      "Current iteration=4800, the loss=4954.124513009164\n",
      "Current iteration=4900, the loss=4949.562086743356\n",
      "Current iteration=5000, the loss=4941.037861619354\n",
      "Current iteration=5100, the loss=4934.496551127142\n",
      "Current iteration=5200, the loss=4947.378235668145\n",
      "Current iteration=5300, the loss=4941.427934279807\n",
      "Current iteration=5400, the loss=4934.755581629001\n",
      "Current iteration=5500, the loss=4929.44406504156\n",
      "Current iteration=5600, the loss=4943.192995317312\n",
      "Current iteration=5700, the loss=4934.67555309846\n",
      "Current iteration=5800, the loss=4932.263721401339\n",
      "Current iteration=5900, the loss=4935.070732856294\n",
      "Current iteration=6000, the loss=4923.622539867524\n",
      "Current iteration=6100, the loss=4920.492126843924\n",
      "Current iteration=6200, the loss=4920.968169703898\n",
      "Current iteration=6300, the loss=4930.198905366729\n",
      "Current iteration=6400, the loss=4923.789408175626\n",
      "Current iteration=6500, the loss=4915.5817965103115\n",
      "Current iteration=6600, the loss=4925.071979511977\n",
      "Current iteration=6700, the loss=4920.36840094013\n",
      "Current iteration=6800, the loss=4925.883716102678\n",
      "Current iteration=6900, the loss=4915.122831020708\n",
      "Current iteration=7000, the loss=4921.753740949886\n",
      "Current iteration=7100, the loss=4916.5546535413405\n",
      "Current iteration=7200, the loss=4922.9939862031415\n",
      "Current iteration=7300, the loss=4911.5288911669295\n",
      "Current iteration=7400, the loss=4909.892296933638\n",
      "Current iteration=7500, the loss=4913.384964938215\n",
      "Current iteration=7600, the loss=4918.696724802362\n",
      "Current iteration=7700, the loss=4909.336980128141\n",
      "Current iteration=7800, the loss=4906.516143763261\n",
      "Current iteration=7900, the loss=4905.212473673873\n",
      "Current iteration=8000, the loss=4907.0499434706735\n",
      "Current iteration=8100, the loss=4904.788058380018\n",
      "Current iteration=8200, the loss=4914.787662942712\n",
      "Current iteration=8300, the loss=4913.362129947435\n",
      "Current iteration=8400, the loss=4910.696101768683\n",
      "Current iteration=8500, the loss=4911.302529209706\n",
      "Current iteration=8600, the loss=4917.108736192524\n",
      "Current iteration=8700, the loss=4902.791092522791\n",
      "Current iteration=8800, the loss=4905.323621723872\n",
      "Current iteration=8900, the loss=4901.750882634386\n",
      "Current iteration=9000, the loss=4906.569782378353\n",
      "Current iteration=9100, the loss=4910.400573043336\n",
      "Current iteration=9200, the loss=4907.422089283989\n",
      "Current iteration=9300, the loss=4909.292184405761\n",
      "Current iteration=9400, the loss=4915.215908379332\n",
      "Current iteration=9500, the loss=4900.97542018242\n",
      "Current iteration=9600, the loss=4898.694289419805\n",
      "Current iteration=9700, the loss=4913.703040796483\n",
      "Current iteration=9800, the loss=4900.698176796821\n",
      "Current iteration=9900, the loss=4914.653512305994\n",
      "Current iteration=10000, the loss=4908.06052256317\n",
      "Current iteration=10100, the loss=4914.780018273594\n",
      "Current iteration=10200, the loss=4910.5848674950075\n",
      "Current iteration=10300, the loss=4914.116697229131\n",
      "Current iteration=10400, the loss=4907.654584003304\n",
      "Current iteration=10500, the loss=4907.483282155125\n",
      "Current iteration=10600, the loss=4905.004435186231\n",
      "Current iteration=10700, the loss=4904.624087896552\n",
      "Current iteration=10800, the loss=4900.935022179265\n",
      "Current iteration=10900, the loss=4910.953100775454\n",
      "Current iteration=11000, the loss=4909.958536349603\n",
      "Current iteration=11100, the loss=4895.986389396885\n",
      "Current iteration=11200, the loss=4896.187693773031\n",
      "Current iteration=11300, the loss=4897.497487943278\n",
      "Current iteration=11400, the loss=4900.970716011096\n",
      "Current iteration=11500, the loss=4904.129226321242\n",
      "Current iteration=11600, the loss=4904.084707603715\n",
      "Current iteration=11700, the loss=4906.316703257874\n",
      "Current iteration=11800, the loss=4907.053945871166\n",
      "Current iteration=11900, the loss=4897.295978969088\n",
      "The loss=4906.24954740005\n",
      "Training error: 4938.310249773891\n",
      "Test error: 5081.149310515388\n",
      "Classification accuracy: 0.8011189316007941\n"
     ]
    }
   ],
   "source": [
    "from toolbox import *\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters_3 = 12000\n",
    "gamma_3 = 1e-6\n",
    "lambda_3 = 0\n",
    "degree_3 = 3\n",
    "batch_size3 = 100\n",
    "k = 2\n",
    "current_y = y3\n",
    "current_X = X3\n",
    "k_indices = build_k_indices(current_y, k, 1)\n",
    "\n",
    "loss_tr = []\n",
    "loss_te = []\n",
    "classification_acc = []\n",
    "for k_ in range(k):\n",
    "\n",
    "    test_indices = k_indices[k_]\n",
    "    test_y, test_x = (current_y[test_indices], current_X[test_indices])\n",
    "    test_x = build_poly(test_x, degree_3)\n",
    "\n",
    "    training_indices = np.ravel(np.delete(k_indices, k_, axis=0))\n",
    "    training_y, training_x = (current_y[training_indices], current_X[training_indices])\n",
    "    training_x = build_poly(training_x, degree_3)\n",
    "\n",
    "    w_star = reg_logistic_regression(training_y, training_x, lambda_3, gamma_3, max_iters_3)\n",
    "    \n",
    "    # compute classification accuracy\n",
    "    y_pred = predict_labels_log_regression(w_star, test_x)\n",
    "    \n",
    "    test_y[test_y == 0] = -1\n",
    "    classification_acc.append(np.mean(np.abs(test_y + y_pred) / 2))\n",
    "    test_y[test_y == -1] = 0\n",
    "\n",
    "    loss_tr.append(calculate_loss_log_likelihood(training_y, training_x, w_star))\n",
    "    loss_te.append(calculate_loss_log_likelihood(test_y, test_x, w_star))\n",
    "        \n",
    "print(\"Training error: {tr}\\nTest error: {te}\\nClassification accuracy: {cl}\".format(tr=np.mean(loss_tr), te=np.mean(loss_te), cl=np.mean(classification_acc)))\n",
    "overall_acc.append(np.mean(classification_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall accuracy: 0.8007403114973887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The overall accuracy: {acc}\\n\".format(acc=np.mean(overall_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=59827.901962343414\n",
      "Current iteration=100, the loss=39310.18955146214\n",
      "Current iteration=200, the loss=38865.471345088095\n",
      "Current iteration=300, the loss=38660.74811632965\n",
      "Current iteration=400, the loss=38519.46500371248\n",
      "Current iteration=500, the loss=38405.90285230931\n",
      "Current iteration=600, the loss=38308.50444148451\n",
      "Current iteration=700, the loss=38222.30110685889\n",
      "Current iteration=800, the loss=38144.637780473335\n",
      "Current iteration=900, the loss=38073.87952268947\n",
      "Current iteration=1000, the loss=38008.924356192074\n",
      "Current iteration=1100, the loss=37948.9808399343\n",
      "Current iteration=1200, the loss=37893.45154015081\n",
      "Current iteration=1300, the loss=37841.866452641756\n",
      "Current iteration=1400, the loss=37793.84284052694\n",
      "Current iteration=1500, the loss=37749.06007715472\n",
      "Current iteration=1600, the loss=37707.243401326166\n",
      "Current iteration=1700, the loss=37668.1531276278\n",
      "Current iteration=1800, the loss=37631.57727374803\n",
      "Current iteration=1900, the loss=37597.32637211277\n",
      "Current iteration=2000, the loss=37565.2297060668\n",
      "Current iteration=2100, the loss=37535.132494858735\n",
      "Current iteration=2200, the loss=37506.89372513052\n",
      "Current iteration=2300, the loss=37480.38443393153\n",
      "Current iteration=2400, the loss=37455.48631545433\n",
      "Current iteration=2500, the loss=37432.09056621096\n",
      "Current iteration=2600, the loss=37410.09691059993\n",
      "Current iteration=2700, the loss=37389.412766475274\n",
      "Current iteration=2800, the loss=37369.95252195119\n",
      "Current iteration=2900, the loss=37351.636902448125\n",
      "Current iteration=3000, the loss=37334.39241228286\n",
      "Current iteration=3100, the loss=37318.15083878655\n",
      "Current iteration=3200, the loss=37302.84880954997\n",
      "Current iteration=3300, the loss=37288.42739529685\n",
      "Current iteration=3400, the loss=37274.83175229679\n",
      "Current iteration=3500, the loss=37262.0107993016\n",
      "Current iteration=3600, the loss=37249.916924818666\n",
      "Current iteration=3700, the loss=37238.505721188616\n",
      "Current iteration=3800, the loss=37227.73574245845\n",
      "Current iteration=3900, the loss=37217.56828346786\n",
      "Current iteration=4000, the loss=37207.9671779153\n",
      "Current iteration=4100, the loss=37198.89861346138\n",
      "Current iteration=4200, the loss=37190.33096217141\n",
      "Current iteration=4300, the loss=37182.23462480397\n",
      "Current iteration=4400, the loss=37174.581887628905\n",
      "Current iteration=4500, the loss=37167.34679060662\n",
      "Current iteration=4600, the loss=37160.5050058918\n",
      "Current iteration=4700, the loss=37154.03372573471\n",
      "Current iteration=4800, the loss=37147.91155895251\n",
      "Current iteration=4900, the loss=37142.118435226555\n",
      "Current iteration=5000, the loss=37136.63551655749\n",
      "Current iteration=5100, the loss=37131.44511527534\n",
      "Current iteration=5200, the loss=37126.53061805987\n",
      "Current iteration=5300, the loss=37121.87641547849\n",
      "Current iteration=5400, the loss=37117.46783659444\n",
      "Current iteration=5500, the loss=37113.29108823954\n",
      "Current iteration=5600, the loss=37109.33319858175\n",
      "Current iteration=5700, the loss=37105.58196465134\n",
      "Current iteration=5800, the loss=37102.02590351831\n",
      "Current iteration=5900, the loss=37098.65420684106\n",
      "Current iteration=6000, the loss=37095.456698529604\n",
      "Current iteration=6100, the loss=37092.42379528862\n",
      "Current iteration=6200, the loss=37089.54646982558\n",
      "Current iteration=6300, the loss=37086.81621652613\n",
      "Current iteration=6400, the loss=37084.22501941584\n",
      "Current iteration=6500, the loss=37081.76532224192\n",
      "Current iteration=6600, the loss=37079.43000052174\n",
      "Current iteration=6700, the loss=37077.21233541707\n",
      "Current iteration=6800, the loss=37075.105989304386\n",
      "Current iteration=6900, the loss=37073.10498292157\n",
      "Current iteration=7000, the loss=37071.2036739803\n",
      "Current iteration=7100, the loss=37069.39673714263\n",
      "Current iteration=7200, the loss=37067.67914526712\n",
      "Current iteration=7300, the loss=37066.04615183784\n",
      "Current iteration=7400, the loss=37064.49327449534\n",
      "Current iteration=7500, the loss=37063.01627959529\n",
      "Current iteration=7600, the loss=37061.6111677256\n",
      "Current iteration=7700, the loss=37060.27416011799\n",
      "Current iteration=7800, the loss=37059.0016858947\n",
      "Current iteration=7900, the loss=37057.79037009536\n",
      "Current iteration=8000, the loss=37056.63702243248\n",
      "Current iteration=8100, the loss=37055.53862672868\n",
      "Current iteration=8200, the loss=37054.492330990855\n",
      "Current iteration=8300, the loss=37053.49543808079\n",
      "Current iteration=8400, the loss=37052.545396943606\n",
      "Current iteration=8500, the loss=37051.63979435862\n",
      "Current iteration=8600, the loss=37050.776347179715\n",
      "Current iteration=8700, the loss=37049.95289503402\n",
      "Current iteration=8800, the loss=37049.16739345022\n",
      "Current iteration=8900, the loss=37048.41790739002\n",
      "Current iteration=9000, the loss=37047.702605157276\n",
      "Current iteration=9100, the loss=37047.01975266166\n",
      "Current iteration=9200, the loss=37046.36770801506\n",
      "Current iteration=9300, the loss=37045.74491644025\n",
      "Current iteration=9400, the loss=37045.14990547292\n",
      "Current iteration=9500, the loss=37044.581280439175\n",
      "Current iteration=9600, the loss=37044.03772019168\n",
      "Current iteration=9700, the loss=37043.517973089336\n",
      "Current iteration=9800, the loss=37043.020853205395\n",
      "Current iteration=9900, the loss=37042.54523675073\n",
      "Current iteration=10000, the loss=37042.09005869935\n",
      "Current iteration=10100, the loss=37041.654309603946\n",
      "Current iteration=10200, the loss=37041.23703259075\n",
      "Current iteration=10300, the loss=37040.83732052272\n",
      "Current iteration=10400, the loss=37040.45431332141\n",
      "Current iteration=10500, the loss=37040.08719543819\n",
      "Current iteration=10600, the loss=37039.735193466106\n",
      "Current iteration=10700, the loss=37039.397573884315\n",
      "Current iteration=10800, the loss=37039.0736409274\n",
      "Current iteration=10900, the loss=37038.76273457229\n",
      "Current iteration=11000, the loss=37038.464228636025\n",
      "Current iteration=11100, the loss=37038.17752897814\n",
      "Current iteration=11200, the loss=37037.902071801924\n",
      "Current iteration=11300, the loss=37037.63732204806\n",
      "Current iteration=11400, the loss=37037.38277187646\n",
      "Current iteration=11500, the loss=37037.13793923061\n",
      "Current iteration=11600, the loss=37036.902366480164\n",
      "Current iteration=11700, the loss=37036.67561913693\n",
      "Current iteration=11800, the loss=37036.45728464061\n",
      "Current iteration=11900, the loss=37036.24697121026\n",
      "Current iteration=12000, the loss=37036.04430675736\n",
      "Current iteration=12100, the loss=37035.8489378578\n",
      "Current iteration=12200, the loss=37035.66052877903\n",
      "Current iteration=12300, the loss=37035.47876055917\n",
      "Current iteration=12400, the loss=37035.30333013583\n",
      "Current iteration=12500, the loss=37035.133949521114\n",
      "Current iteration=12600, the loss=37034.97034502112\n",
      "Current iteration=12700, the loss=37034.812256496574\n",
      "Current iteration=12800, the loss=37034.65943666309\n",
      "Current iteration=12900, the loss=37034.51165042854\n",
      "Current iteration=13000, the loss=37034.36867426547\n",
      "Current iteration=13100, the loss=37034.23029561686\n",
      "Current iteration=13200, the loss=37034.09631233332\n",
      "Current iteration=13300, the loss=37033.96653213975\n",
      "Current iteration=13400, the loss=37033.840772130505\n",
      "Current iteration=13500, the loss=37033.71885829083\n",
      "Current iteration=13600, the loss=37033.60062504341\n",
      "Current iteration=13700, the loss=37033.48591481905\n",
      "Current iteration=13800, the loss=37033.3745776495\n",
      "Current iteration=13900, the loss=37033.26647078174\n",
      "Current iteration=14000, the loss=37033.16145831245\n",
      "Current iteration=14100, the loss=37033.059410841495\n",
      "Current iteration=14200, the loss=37032.96020514343\n",
      "Current iteration=14300, the loss=37032.8637238562\n",
      "Current iteration=14400, the loss=37032.76985518598\n",
      "Current iteration=14500, the loss=37032.678492627296\n",
      "Current iteration=14600, the loss=37032.58953469769\n",
      "Current iteration=14700, the loss=37032.50288468611\n",
      "Current iteration=14800, the loss=37032.418450414276\n",
      "Current iteration=14900, the loss=37032.33614401049\n",
      "The loss=37032.25667446531\n",
      "Current iteration=0, the loss=52159.73381580636\n",
      "Current iteration=100, the loss=44201.071390654244\n",
      "Current iteration=200, the loss=42118.49471887837\n",
      "Current iteration=300, the loss=40782.23475903752\n",
      "Current iteration=400, the loss=41096.30583327795\n",
      "Current iteration=500, the loss=40115.77889572599\n",
      "Current iteration=600, the loss=38905.75836695846\n",
      "Current iteration=700, the loss=38475.07253669831\n",
      "Current iteration=800, the loss=38645.69260724461\n",
      "Current iteration=900, the loss=38016.18115181832\n",
      "Current iteration=1000, the loss=38439.34033146221\n",
      "Current iteration=1100, the loss=37570.74916506652\n",
      "Current iteration=1200, the loss=37451.51664545096\n",
      "Current iteration=1300, the loss=37336.88571814552\n",
      "Current iteration=1400, the loss=38210.95786619481\n",
      "Current iteration=1500, the loss=37114.35645163238\n",
      "Current iteration=1600, the loss=37861.28085628449\n",
      "Current iteration=1700, the loss=36913.605538105\n",
      "Current iteration=1800, the loss=36876.267604731984\n",
      "Current iteration=1900, the loss=37865.57753482924\n",
      "Current iteration=2000, the loss=36785.66750742345\n",
      "Current iteration=2100, the loss=37128.52026265964\n",
      "Current iteration=2200, the loss=36946.35892127699\n",
      "Current iteration=2300, the loss=37433.86395627014\n",
      "Current iteration=2400, the loss=36560.79974706916\n",
      "Current iteration=2500, the loss=36795.68771125782\n",
      "Current iteration=2600, the loss=37178.03832449689\n",
      "Current iteration=2700, the loss=36589.67976673501\n",
      "Current iteration=2800, the loss=37172.69702131141\n",
      "Current iteration=2900, the loss=37114.80935896036\n",
      "Current iteration=3000, the loss=36579.1317833116\n",
      "Current iteration=3100, the loss=37059.727402755285\n",
      "Current iteration=3200, the loss=36396.06992601777\n",
      "Current iteration=3300, the loss=37164.74628419583\n",
      "Current iteration=3400, the loss=37142.630157652064\n",
      "Current iteration=3500, the loss=36843.25959097018\n",
      "Current iteration=3600, the loss=36337.010408407026\n",
      "Current iteration=3700, the loss=36348.60820115385\n",
      "Current iteration=3800, the loss=36379.28454524132\n",
      "Current iteration=3900, the loss=36394.607309856714\n",
      "Current iteration=4000, the loss=36418.51956561646\n",
      "Current iteration=4100, the loss=36231.527601915965\n",
      "Current iteration=4200, the loss=36280.0493070789\n",
      "Current iteration=4300, the loss=36279.824699640594\n",
      "Current iteration=4400, the loss=36234.07689219175\n",
      "Current iteration=4500, the loss=36183.07327590704\n",
      "Current iteration=4600, the loss=36297.1890246423\n",
      "Current iteration=4700, the loss=36517.93648474713\n",
      "Current iteration=4800, the loss=36385.37128752173\n",
      "Current iteration=4900, the loss=36162.13000327429\n",
      "Current iteration=5000, the loss=36325.10186801615\n",
      "Current iteration=5100, the loss=36158.50155690811\n",
      "Current iteration=5200, the loss=36165.20913340602\n",
      "Current iteration=5300, the loss=36133.211109774886\n",
      "Current iteration=5400, the loss=36116.667633093704\n",
      "Current iteration=5500, the loss=36293.6758977039\n",
      "Current iteration=5600, the loss=36113.508469007196\n",
      "Current iteration=5700, the loss=36102.6318995883\n",
      "Current iteration=5800, the loss=36146.833323989755\n",
      "Current iteration=5900, the loss=36103.83956798733\n",
      "Current iteration=6000, the loss=36178.124151341435\n",
      "Current iteration=6100, the loss=36102.88911300298\n",
      "Current iteration=6200, the loss=36404.02935277537\n",
      "Current iteration=6300, the loss=36088.593282588845\n",
      "Current iteration=6400, the loss=36109.078344905574\n",
      "Current iteration=6500, the loss=36257.649499261664\n",
      "Current iteration=6600, the loss=36214.124521373844\n",
      "Current iteration=6700, the loss=36070.2375813823\n",
      "Current iteration=6800, the loss=36084.50148217499\n",
      "Current iteration=6900, the loss=36539.11747887536\n",
      "Current iteration=7000, the loss=36748.6362695382\n",
      "Current iteration=7100, the loss=36813.93841018263\n",
      "Current iteration=7200, the loss=36550.60818488352\n",
      "Current iteration=7300, the loss=36595.75558618562\n",
      "Current iteration=7400, the loss=36056.69965543256\n",
      "Current iteration=7500, the loss=36038.4637962606\n",
      "Current iteration=7600, the loss=36101.07098746115\n",
      "Current iteration=7700, the loss=36040.941171832965\n",
      "Current iteration=7800, the loss=36126.6246395082\n",
      "Current iteration=7900, the loss=36048.45926247145\n",
      "Current iteration=8000, the loss=36031.9112398598\n",
      "Current iteration=8100, the loss=36024.29515411863\n",
      "Current iteration=8200, the loss=36327.2552584953\n",
      "Current iteration=8300, the loss=36048.38319803248\n",
      "Current iteration=8400, the loss=36223.778216989944\n",
      "Current iteration=8500, the loss=36015.180253292405\n",
      "Current iteration=8600, the loss=36327.79574428744\n",
      "Current iteration=8700, the loss=36664.21350352568\n",
      "Current iteration=8800, the loss=36557.83622249366\n",
      "Current iteration=8900, the loss=36058.926807684606\n",
      "Current iteration=9000, the loss=36443.16394516852\n",
      "Current iteration=9100, the loss=36277.273650324\n",
      "Current iteration=9200, the loss=36105.947300284126\n",
      "Current iteration=9300, the loss=36233.52960088677\n",
      "Current iteration=9400, the loss=36007.51059469654\n",
      "Current iteration=9500, the loss=36774.19587397282\n",
      "Current iteration=9600, the loss=36472.84237125459\n",
      "Current iteration=9700, the loss=36676.40364346186\n",
      "Current iteration=9800, the loss=36755.54870996918\n",
      "Current iteration=9900, the loss=36549.83813964043\n",
      "Current iteration=10000, the loss=36628.231619205966\n",
      "Current iteration=10100, the loss=36767.69793870576\n",
      "Current iteration=10200, the loss=36751.81613734199\n",
      "Current iteration=10300, the loss=36482.31327128818\n",
      "Current iteration=10400, the loss=36749.84625737219\n",
      "Current iteration=10500, the loss=36451.85579666324\n",
      "Current iteration=10600, the loss=36760.566399133415\n",
      "Current iteration=10700, the loss=36191.03613241494\n",
      "Current iteration=10800, the loss=36287.57139850051\n",
      "Current iteration=10900, the loss=36099.694782509134\n",
      "Current iteration=11000, the loss=35989.08145132793\n",
      "Current iteration=11100, the loss=36280.85524871042\n",
      "Current iteration=11200, the loss=36096.23859587962\n",
      "Current iteration=11300, the loss=35986.71393121766\n",
      "Current iteration=11400, the loss=36276.00758650333\n",
      "Current iteration=11500, the loss=36093.41702228196\n",
      "Current iteration=11600, the loss=35984.5091344607\n",
      "Current iteration=11700, the loss=36271.44707106327\n",
      "Current iteration=11800, the loss=36090.71774859511\n",
      "Current iteration=11900, the loss=35982.44518480741\n",
      "Current iteration=12000, the loss=36266.988045473474\n",
      "Current iteration=12100, the loss=36087.980920891336\n",
      "Current iteration=12200, the loss=35980.50888449393\n",
      "Current iteration=12300, the loss=36262.578606446405\n",
      "Current iteration=12400, the loss=36085.04634995824\n",
      "Current iteration=12500, the loss=35978.737040765576\n",
      "Current iteration=12600, the loss=36256.22871375938\n",
      "Current iteration=12700, the loss=36085.34788208406\n",
      "Current iteration=12800, the loss=36179.45280514108\n",
      "Current iteration=12900, the loss=35982.70907383062\n",
      "Current iteration=13000, the loss=35981.56051507353\n",
      "Current iteration=13100, the loss=36621.565243006946\n",
      "Current iteration=13200, the loss=36719.15372570533\n",
      "Current iteration=13300, the loss=36562.59271341791\n",
      "Current iteration=13400, the loss=36728.43150552416\n",
      "Current iteration=13500, the loss=36429.35743365547\n",
      "Current iteration=13600, the loss=36392.40093480209\n",
      "Current iteration=13700, the loss=36474.402214513815\n",
      "Current iteration=13800, the loss=36688.80290487056\n",
      "Current iteration=13900, the loss=36588.24925839797\n",
      "Current iteration=14000, the loss=36590.77157026518\n",
      "Current iteration=14100, the loss=36575.60720566353\n",
      "Current iteration=14200, the loss=36729.451116787546\n",
      "Current iteration=14300, the loss=36600.415698613724\n",
      "Current iteration=14400, the loss=36719.699187141014\n",
      "Current iteration=14500, the loss=36722.57209752886\n",
      "Current iteration=14600, the loss=36502.75242605853\n",
      "Current iteration=14700, the loss=36736.859621627475\n",
      "Current iteration=14800, the loss=36692.617027507986\n",
      "Current iteration=14900, the loss=36734.41881971467\n",
      "The loss=36023.94799598186\n",
      "Current iteration=0, the loss=33366.69694273369\n",
      "Current iteration=100, the loss=24674.01679923147\n",
      "Current iteration=200, the loss=23616.322784418444\n",
      "Current iteration=300, the loss=23078.36556817369\n",
      "Current iteration=400, the loss=22759.834188240926\n",
      "Current iteration=500, the loss=22556.284290367657\n",
      "Current iteration=600, the loss=22419.712063495354\n",
      "Current iteration=700, the loss=22324.887198057382\n",
      "Current iteration=800, the loss=22257.34306107836\n",
      "Current iteration=900, the loss=22208.255111012484\n",
      "Current iteration=1000, the loss=22171.98670402378\n",
      "Current iteration=1100, the loss=22144.808053929024\n",
      "Current iteration=1200, the loss=22124.18189808458\n",
      "Current iteration=1300, the loss=22108.34366626929\n",
      "Current iteration=1400, the loss=22096.043974477114\n",
      "Current iteration=1500, the loss=22086.38504409352\n",
      "Current iteration=1600, the loss=22078.713726694717\n",
      "Current iteration=1700, the loss=22072.549834504913\n",
      "Current iteration=1800, the loss=22067.537140081207\n",
      "Current iteration=1900, the loss=22063.4092944457\n",
      "Current iteration=2000, the loss=22059.965771165815\n",
      "Current iteration=2100, the loss=22057.05467078888\n",
      "Current iteration=2200, the loss=22054.560293160757\n",
      "Current iteration=2300, the loss=22052.39406859561\n",
      "Current iteration=2400, the loss=22050.487883574373\n",
      "Current iteration=2500, the loss=22048.789131526122\n",
      "Current iteration=2600, the loss=22047.25701805365\n",
      "Current iteration=2700, the loss=22045.859785992245\n",
      "Current iteration=2800, the loss=22044.57261999796\n",
      "Current iteration=2900, the loss=22043.376056521898\n",
      "Current iteration=3000, the loss=22042.25477193881\n",
      "Current iteration=3100, the loss=22041.19665518248\n",
      "Current iteration=3200, the loss=22040.19209549835\n",
      "Current iteration=3300, the loss=22039.233433582085\n",
      "Current iteration=3400, the loss=22038.314537324302\n",
      "Current iteration=3500, the loss=22037.43047294284\n",
      "Current iteration=3600, the loss=22036.577249385387\n",
      "Current iteration=3700, the loss=22035.751619191076\n",
      "Current iteration=3800, the loss=22034.95092298172\n",
      "Current iteration=3900, the loss=22034.172967759136\n",
      "Current iteration=4000, the loss=22033.415931460164\n",
      "Current iteration=4100, the loss=22032.678287953793\n",
      "Current iteration=4200, the loss=22031.958747986006\n",
      "Current iteration=4300, the loss=22031.25621259104\n",
      "Current iteration=4400, the loss=22030.56973626576\n",
      "Current iteration=4500, the loss=22029.898497803617\n",
      "Current iteration=4600, the loss=22029.241777148032\n",
      "Current iteration=4700, the loss=22028.598936983748\n",
      "Current iteration=4800, the loss=22027.96940806348\n",
      "Current iteration=4900, the loss=22027.352677483992\n",
      "Current iteration=5000, the loss=22026.748279294305\n",
      "Current iteration=5100, the loss=22026.155786950985\n",
      "Current iteration=5200, the loss=22025.574807238518\n",
      "Current iteration=5300, the loss=22025.00497535395\n",
      "Current iteration=5400, the loss=22024.4459509172\n",
      "Current iteration=5500, the loss=22023.89741472032\n",
      "Current iteration=5600, the loss=22023.35906606589\n",
      "Current iteration=5700, the loss=22022.830620577508\n",
      "Current iteration=5800, the loss=22022.311808388607\n",
      "Current iteration=5900, the loss=22021.80237263524\n",
      "Current iteration=6000, the loss=22021.30206819398\n",
      "Current iteration=6100, the loss=22020.810660617914\n",
      "Current iteration=6200, the loss=22020.32792523307\n",
      "Current iteration=6300, the loss=22019.85364636527\n",
      "Current iteration=6400, the loss=22019.387616674\n",
      "Current iteration=6500, the loss=22018.92963657326\n",
      "Current iteration=6600, the loss=22018.479513724706\n",
      "Current iteration=6700, the loss=22018.037062590338\n",
      "Current iteration=6800, the loss=22017.602104034704\n",
      "Current iteration=6900, the loss=22017.174464968877\n",
      "Current iteration=7000, the loss=22016.75397802925\n",
      "Current iteration=7100, the loss=22016.340481286177\n",
      "Current iteration=7200, the loss=22015.9338179779\n",
      "Current iteration=7300, the loss=22015.533836266302\n",
      "Current iteration=7400, the loss=22015.14038901172\n",
      "Current iteration=7500, the loss=22014.753333563982\n",
      "Current iteration=7600, the loss=22014.372531568282\n",
      "Current iteration=7700, the loss=22013.997848783605\n",
      "Current iteration=7800, the loss=22013.629154912887\n",
      "Current iteration=7900, the loss=22013.26632344316\n",
      "Current iteration=8000, the loss=22012.909231495374\n",
      "Current iteration=8100, the loss=22012.55775968211\n",
      "Current iteration=8200, the loss=22012.211791973605\n",
      "Current iteration=8300, the loss=22011.871215570332\n",
      "Current iteration=8400, the loss=22011.53592078237\n",
      "Current iteration=8500, the loss=22011.20580091476\n",
      "Current iteration=8600, the loss=22010.880752158286\n",
      "Current iteration=8700, the loss=22010.560673485772\n",
      "Current iteration=8800, the loss=22010.245466552893\n",
      "Current iteration=8900, the loss=22009.935035603878\n",
      "Current iteration=9000, the loss=22009.62928738124\n",
      "Current iteration=9100, the loss=22009.32813103964\n",
      "Current iteration=9200, the loss=22009.031478063596\n",
      "Current iteration=9300, the loss=22008.73924218864\n",
      "Current iteration=9400, the loss=22008.451339325977\n",
      "Current iteration=9500, the loss=22008.167687490277\n",
      "Current iteration=9600, the loss=22007.888206730524\n",
      "Current iteration=9700, the loss=22007.612819063703\n",
      "Current iteration=9800, the loss=22007.341448411244\n",
      "Current iteration=9900, the loss=22007.074020538086\n",
      "Current iteration=10000, the loss=22006.810462994174\n",
      "Current iteration=10100, the loss=22006.55070505821\n",
      "Current iteration=10200, the loss=22006.294677683814\n",
      "Current iteration=10300, the loss=22006.0423134476\n",
      "Current iteration=10400, the loss=22005.79354649948\n",
      "Current iteration=10500, the loss=22005.548312514657\n",
      "Current iteration=10600, the loss=22005.306548647713\n",
      "Current iteration=10700, the loss=22005.06819348818\n",
      "Current iteration=10800, the loss=22004.833187018055\n",
      "Current iteration=10900, the loss=22004.60147057067\n",
      "Current iteration=11000, the loss=22004.372986791197\n",
      "Current iteration=11100, the loss=22004.147679598645\n",
      "Current iteration=11200, the loss=22003.925494149174\n",
      "Current iteration=11300, the loss=22003.70637680072\n",
      "Current iteration=11400, the loss=22003.490275078984\n",
      "Current iteration=11500, the loss=22003.27713764464\n",
      "Current iteration=11600, the loss=22003.06691426155\n",
      "Current iteration=11700, the loss=22002.859555766227\n",
      "Current iteration=11800, the loss=22002.6550140384\n",
      "Current iteration=11900, the loss=22002.453241972515\n",
      "Current iteration=12000, the loss=22002.254193450215\n",
      "Current iteration=12100, the loss=22002.057823313815\n",
      "Current iteration=12200, the loss=22001.864087340662\n",
      "Current iteration=12300, the loss=22001.672942218334\n",
      "Current iteration=12400, the loss=22001.48434552065\n",
      "Current iteration=12500, the loss=22001.298255684596\n",
      "Current iteration=12600, the loss=22001.114631987868\n",
      "Current iteration=12700, the loss=22000.933434527207\n",
      "Current iteration=12800, the loss=22000.754624197485\n",
      "Current iteration=12900, the loss=22000.578162671372\n",
      "Current iteration=13000, the loss=22000.404012379753\n",
      "Current iteration=13100, the loss=22000.232136492727\n",
      "Current iteration=13200, the loss=22000.062498901127\n",
      "Current iteration=13300, the loss=21999.895064198827\n",
      "Current iteration=13400, the loss=21999.729797665343\n",
      "Current iteration=13500, the loss=21999.566665249222\n",
      "Current iteration=13600, the loss=21999.40563355173\n",
      "Current iteration=13700, the loss=21999.246669811175\n",
      "Current iteration=13800, the loss=21999.089741887678\n",
      "Current iteration=13900, the loss=21998.934818248366\n",
      "Current iteration=14000, the loss=21998.781867953054\n",
      "Current iteration=14100, the loss=21998.630860640347\n",
      "Current iteration=14200, the loss=21998.481766514073\n",
      "Current iteration=14300, the loss=21998.334556330265\n",
      "Current iteration=14400, the loss=21998.189201384404\n",
      "Current iteration=14500, the loss=21998.04567349906\n",
      "Current iteration=14600, the loss=21997.903945011953\n",
      "Current iteration=14700, the loss=21997.763988764214\n",
      "Current iteration=14800, the loss=21997.625778089146\n",
      "Current iteration=14900, the loss=21997.48928680118\n",
      "The loss=21997.35582886103\n",
      "Current iteration=0, the loss=14509.269234229809\n",
      "Current iteration=100, the loss=12027.878699512055\n",
      "Current iteration=200, the loss=11525.542692714793\n",
      "Current iteration=300, the loss=11539.81780084256\n",
      "Current iteration=400, the loss=11090.629716482677\n",
      "Current iteration=500, the loss=10964.148857123913\n",
      "Current iteration=600, the loss=10893.358846677456\n",
      "Current iteration=700, the loss=10711.88553675251\n",
      "Current iteration=800, the loss=10658.65413755188\n",
      "Current iteration=900, the loss=10558.176842725954\n",
      "Current iteration=1000, the loss=10489.984700272658\n",
      "Current iteration=1100, the loss=10503.648686992796\n",
      "Current iteration=1200, the loss=10388.57930298486\n",
      "Current iteration=1300, the loss=10420.48533260615\n",
      "Current iteration=1400, the loss=10352.45904784813\n",
      "Current iteration=1500, the loss=10337.22907427823\n",
      "Current iteration=1600, the loss=10266.70752600411\n",
      "Current iteration=1700, the loss=10286.954929336054\n",
      "Current iteration=1800, the loss=10265.580601964895\n",
      "Current iteration=1900, the loss=10232.179634180675\n",
      "Current iteration=2000, the loss=10236.369216096109\n",
      "Current iteration=2100, the loss=10233.68225528479\n",
      "Current iteration=2200, the loss=10170.525685635455\n",
      "Current iteration=2300, the loss=10193.239530687839\n",
      "Current iteration=2400, the loss=10145.663602969658\n",
      "Current iteration=2500, the loss=10185.855516167752\n",
      "Current iteration=2600, the loss=10197.822231418024\n",
      "Current iteration=2700, the loss=10157.849080878519\n",
      "Current iteration=2800, the loss=10118.974557237625\n",
      "Current iteration=2900, the loss=10117.718291692609\n",
      "Current iteration=3000, the loss=10202.755361950194\n",
      "Current iteration=3100, the loss=10103.0316409689\n",
      "Current iteration=3200, the loss=10134.921345089944\n",
      "Current iteration=3300, the loss=10251.878131297342\n",
      "Current iteration=3400, the loss=10211.685575383264\n",
      "Current iteration=3500, the loss=10242.361311069657\n",
      "Current iteration=3600, the loss=10204.754395785782\n",
      "Current iteration=3700, the loss=10234.231751966969\n",
      "Current iteration=3800, the loss=10199.283792945977\n",
      "Current iteration=3900, the loss=10227.836301307942\n",
      "Current iteration=4000, the loss=10195.274784836287\n",
      "Current iteration=4100, the loss=10223.062497258366\n",
      "Current iteration=4200, the loss=10193.759364978487\n",
      "Current iteration=4300, the loss=10224.737999689163\n",
      "Current iteration=4400, the loss=10182.955385343586\n",
      "Current iteration=4500, the loss=10223.008098937984\n",
      "Current iteration=4600, the loss=10217.04518502996\n",
      "Current iteration=4700, the loss=10238.35899291053\n",
      "Current iteration=4800, the loss=10208.425036507351\n",
      "Current iteration=4900, the loss=10239.996931807395\n",
      "Current iteration=5000, the loss=10228.983345488967\n",
      "Current iteration=5100, the loss=10239.111640810206\n",
      "Current iteration=5200, the loss=10224.09839379563\n",
      "Current iteration=5300, the loss=10232.827658472064\n",
      "Current iteration=5400, the loss=10198.896176218537\n",
      "Current iteration=5500, the loss=10225.834690591697\n",
      "Current iteration=5600, the loss=10235.87147442002\n",
      "Current iteration=5700, the loss=10210.209213668966\n",
      "Current iteration=5800, the loss=10200.538635579636\n",
      "Current iteration=5900, the loss=10234.029462442297\n",
      "Current iteration=6000, the loss=10232.930111013078\n",
      "Current iteration=6100, the loss=10231.813255934203\n",
      "Current iteration=6200, the loss=10230.709651373389\n",
      "Current iteration=6300, the loss=10229.629627047732\n",
      "Current iteration=6400, the loss=10228.576038843088\n",
      "Current iteration=6500, the loss=10227.548235361253\n",
      "Current iteration=6600, the loss=10226.543098277587\n",
      "Current iteration=6700, the loss=10225.554383122995\n",
      "Current iteration=6800, the loss=10224.568432843625\n",
      "Current iteration=6900, the loss=10223.538069692366\n",
      "Current iteration=7000, the loss=10221.453696487368\n",
      "Current iteration=7100, the loss=10215.289115798738\n",
      "Current iteration=7200, the loss=10209.726346301391\n",
      "Current iteration=7300, the loss=10219.709655532795\n",
      "Current iteration=7400, the loss=10219.847457628857\n",
      "Current iteration=7500, the loss=10214.15010908012\n",
      "Current iteration=7600, the loss=10212.83302740354\n",
      "Current iteration=7700, the loss=10212.12448651085\n",
      "Current iteration=7800, the loss=10212.954385759629\n",
      "Current iteration=7900, the loss=10210.012804229827\n",
      "Current iteration=8000, the loss=10193.112011368548\n",
      "Current iteration=8100, the loss=10210.31738913391\n",
      "Current iteration=8200, the loss=10207.433934872153\n",
      "Current iteration=8300, the loss=10207.244082114352\n",
      "Current iteration=8400, the loss=10209.105458098391\n",
      "Current iteration=8500, the loss=10204.977524926095\n",
      "Current iteration=8600, the loss=10207.714310802989\n",
      "Current iteration=8700, the loss=10204.086515150635\n",
      "Current iteration=8800, the loss=10206.756057771856\n",
      "Current iteration=8900, the loss=10203.072367787036\n",
      "Current iteration=9000, the loss=10209.529044744846\n",
      "Current iteration=9100, the loss=10195.471761024792\n",
      "Current iteration=9200, the loss=10205.682276786516\n",
      "Current iteration=9300, the loss=10194.874055481316\n",
      "Current iteration=9400, the loss=10206.89504427631\n",
      "Current iteration=9500, the loss=10190.442012512558\n",
      "Current iteration=9600, the loss=10203.836173587022\n",
      "Current iteration=9700, the loss=10197.472705489765\n",
      "Current iteration=9800, the loss=10205.958510599485\n",
      "Current iteration=9900, the loss=10190.12028120006\n",
      "Current iteration=10000, the loss=10201.49789643459\n",
      "Current iteration=10100, the loss=10197.100504249674\n",
      "Current iteration=10200, the loss=10203.866514085119\n",
      "Current iteration=10300, the loss=10189.804202382533\n",
      "Current iteration=10400, the loss=10201.084718657203\n",
      "Current iteration=10500, the loss=10194.626343940237\n",
      "Current iteration=10600, the loss=10202.561892109521\n",
      "Current iteration=10700, the loss=10188.01721232615\n",
      "Current iteration=10800, the loss=10198.973592987462\n",
      "Current iteration=10900, the loss=10193.382128686264\n",
      "Current iteration=11000, the loss=10201.25490534362\n",
      "Current iteration=11100, the loss=10187.10510555874\n",
      "Current iteration=11200, the loss=10197.910719411206\n",
      "Current iteration=11300, the loss=10191.852502841524\n",
      "Current iteration=11400, the loss=10199.861241663806\n",
      "Current iteration=11500, the loss=10186.15175618094\n",
      "Current iteration=11600, the loss=10196.763364271592\n",
      "Current iteration=11700, the loss=10190.328109105183\n",
      "Current iteration=11800, the loss=10198.550994446328\n",
      "Current iteration=11900, the loss=10185.25920279883\n",
      "Current iteration=12000, the loss=10195.705337191184\n",
      "Current iteration=12100, the loss=10188.83176654514\n",
      "Current iteration=12200, the loss=10197.2774450892\n",
      "Current iteration=12300, the loss=10184.4403318311\n",
      "Current iteration=12400, the loss=10194.731577562106\n",
      "Current iteration=12500, the loss=10187.343624425503\n",
      "Current iteration=12600, the loss=10196.024141214752\n",
      "Current iteration=12700, the loss=10183.714040496981\n",
      "Current iteration=12800, the loss=10193.851331921518\n",
      "Current iteration=12900, the loss=10185.833505005196\n",
      "Current iteration=13000, the loss=10194.76203571979\n",
      "Current iteration=13100, the loss=10183.120454631457\n",
      "Current iteration=13200, the loss=10193.089286718843\n",
      "Current iteration=13300, the loss=10184.255500824163\n",
      "Current iteration=13400, the loss=10193.433772373935\n",
      "Current iteration=13500, the loss=10182.702830402208\n",
      "Current iteration=13600, the loss=10192.44082399598\n",
      "Current iteration=13700, the loss=10182.727431312098\n",
      "Current iteration=13800, the loss=10192.128674352025\n",
      "Current iteration=13900, the loss=10182.11691944027\n",
      "Current iteration=14000, the loss=10191.592012640116\n",
      "Current iteration=14100, the loss=10181.686541598428\n",
      "Current iteration=14200, the loss=10191.108169655041\n",
      "Current iteration=14300, the loss=10181.239910695545\n",
      "Current iteration=14400, the loss=10190.628127811351\n",
      "Current iteration=14500, the loss=10180.801936579872\n",
      "Current iteration=14600, the loss=10190.155843711522\n",
      "Current iteration=14700, the loss=10180.370706740694\n",
      "Current iteration=14800, the loss=10189.690778875325\n",
      "Current iteration=14900, the loss=10179.946047670954\n",
      "The loss=10102.233315085597\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "\n",
    "gamma_0 = 1e-6\n",
    "max_iters_0 = 15000\n",
    "degree_0 = 2\n",
    "\n",
    "max_iters_1 = 15000\n",
    "gamma_1 = 1e-7\n",
    "degree_1 = 3\n",
    "\n",
    "max_iters_2 = 15000\n",
    "gamma_2 = 1e-6\n",
    "degree_2 = 2\n",
    "\n",
    "max_iters_3 = 15000\n",
    "gamma_3 = 1e-6\n",
    "degree_3 = 3\n",
    "\n",
    "X0, X1, X2, X3, indices0, indices1, indices2, indices3 = separate_data(X)\n",
    "y0 = y[indices0]\n",
    "y1 = y[indices1]\n",
    "y2 = y[indices2]\n",
    "y3 = y[indices3]\n",
    "\n",
    "\n",
    "phi_X0 = build_poly(X0, degree_0)\n",
    "phi_X1 = build_poly(X1, degree_1)\n",
    "phi_X2 = build_poly(X2, degree_2)\n",
    "phi_X3 = build_poly(X3, degree_3)\n",
    "\n",
    "w0 = reg_logistic_regression(y0, phi_X0, 0, gamma_0, max_iters_0)\n",
    "w1 = reg_logistic_regression(y1, phi_X1, 0, gamma_1, max_iters_1)\n",
    "w2 = reg_logistic_regression(y2, phi_X2, 0, gamma_2, max_iters_2)\n",
    "w3 = reg_logistic_regression(y3, phi_X3, 0, gamma_3, max_iters_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "X0_te, X1_te, X2_te, X3_te, indices0_te, indices1_te, indices2_te, indices3_te = separate_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../submission.csv' # TODO: fill in desired name of output file for submission\n",
    "ids_test0 = ids_test[indices0_te]\n",
    "ids_test1 = ids_test[indices1_te]\n",
    "ids_test2 = ids_test[indices2_te]\n",
    "ids_test3 = ids_test[indices3_te]\n",
    "\n",
    "phi_X0_te = build_poly(X0_te, degree_0)\n",
    "phi_X1_te = build_poly(X1_te, degree_1)\n",
    "phi_X2_te = build_poly(X2_te, degree_2)\n",
    "phi_X3_te = build_poly(X3_te, degree_3)\n",
    "\n",
    "pred0 = predict_labels_log_regression(w0, phi_X0_te)\n",
    "pred1 = predict_labels_log_regression(w1, phi_X1_te)\n",
    "pred2 = predict_labels_log_regression(w2, phi_X2_te)\n",
    "pred3 = predict_labels_log_regression(w3, phi_X3_te)\n",
    "\n",
    "predictions = np.append(pred0, np.append(pred1, np.append(pred2, pred3)))\n",
    "ids = np.append(ids_test0, np.append(ids_test1, np.append(ids_test2, ids_test3)))\n",
    "\n",
    "create_csv_submission(ids, predictions, OUTPUT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
